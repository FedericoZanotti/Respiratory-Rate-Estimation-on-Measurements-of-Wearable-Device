{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HDA project",
      "provenance": [],
      "collapsed_sections": [
        "ofc6XMEpp1hX",
        "9E5igOK1p7MG",
        "x1x6s9U60jFk"
      ],
      "machine_shape": "hm",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYi_rSl6Rblw",
        "outputId": "b15ad8f1-bff7-4d68-fe25-2fe80983ec50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/HDA project/Csv Recordings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCGsXJ6kwoIE",
        "outputId": "d3232c70-e969-4aa5-b84b-c7f5c495e254"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/HDA project/Csv Recordings\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import "
      ],
      "metadata": {
        "id": "ofc6XMEpp1hX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "import time\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from scipy import signal\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ],
      "metadata": {
        "id": "MU33H5Tpww1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utility\n",
        "\n"
      ],
      "metadata": {
        "id": "9E5igOK1p7MG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## This function return\n",
        "\n",
        "def data_load_for_recordings(csvs):\n",
        "  '''\n",
        "  Input:\n",
        "    csvs: list of csv files\n",
        "  Output:\n",
        "    a list of dataframe well formatted\n",
        "  '''\n",
        "  res=[]\n",
        "  for f in csvs:\n",
        "    print(f)\n",
        "    label=f.split(sep='_')[1]\n",
        "    dftemp=pd.read_csv(f, sep='\\t')\n",
        "    cols=list(dftemp.columns)\n",
        "    dftemp.drop(cols[:4], axis=1, inplace = True)\n",
        "    dftemp.dropna(axis=0, inplace=True) \n",
        "    prova=pd.to_datetime(dftemp.OXYTimestamps[len(dftemp.OXYTimestamps)-1]-dftemp.OXYTimestamps[0], unit='ms')\n",
        "    # print(prova)\n",
        "    a_timedelta = prova - datetime.datetime(1970, 1, 1)\n",
        "    seconds = a_timedelta.total_seconds()\n",
        "    # print(\"file \" ,f, \"\\nseconds\", seconds)\n",
        "    res.append(dftemp) \n",
        "  return res "
      ],
      "metadata": {
        "id": "gRuSKoD2ccHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(data_load_for_recordings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pqYqjxMY9Ny",
        "outputId": "c6063974-72fd-48c5-f93b-1bc026bb4b54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function data_load_for_recordings in module __main__:\n",
            "\n",
            "data_load_for_recordings(csvs)\n",
            "    Input:\n",
            "      csvs: list of csv files\n",
            "    Output:\n",
            "      a list of dataframe well formatted\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_long_record(data,freq,sec_to_split=60):\n",
        "  '''\n",
        "  Input:\n",
        "    data: DataFrame\n",
        "    freq: sample rate\n",
        "    sec_to_split: window size\n",
        "  Output:\n",
        "    a list of dataframe splitted\n",
        "  '''\n",
        "\n",
        "  df_splitted=[]; j=0; i=1\n",
        "  samples_one_minute= int(np.round(freq*sec_to_split))\n",
        "  while data.shape[0]>samples_one_minute*i:\n",
        "    # print(data.iloc[j:samples_one_minute*i])\n",
        "    df_splitted.append(data.iloc[j:samples_one_minute*i])\n",
        "    j=samples_one_minute*i\n",
        "    i +=1\n",
        "\n",
        "  print(\"missing ---> \", data.shape[0]-j, \"rows\")\n",
        "  return df_splitted"
      ],
      "metadata": {
        "id": "ii6KYoW1yGG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def assign_label(dfs):\n",
        "  '''\n",
        "  This functions assign the label of the data recorded by the sensor\n",
        "\n",
        "  Input:\n",
        "      dfs: DataFrame\n",
        "  Output:\n",
        "      a list of dataframe with the right label.\n",
        "  \n",
        "  '''\n",
        "\n",
        "  root2='/content/drive/MyDrive/HDA project/Labels'\n",
        "  txts=[]; dfprova=[];\n",
        "  for dirpath, dirnames, filenames in os.walk(root2):\n",
        "    for file in filenames:\n",
        "        txts.append(dirpath + '/' + file)\n",
        "  txts.sort()\n",
        "  # print(txts)\n",
        "  for i in range(len(txts)-2):\n",
        "    tempdf = split_long_record(dfs[7+i],60)\n",
        "    with open(txts[i]) as f:\n",
        "      lines = f.readlines()\n",
        "      # print(lines)\n",
        "      labels_from_file =[0 if j=='Na\\n' else int(j) for j in lines]\n",
        "      for j in range(len(labels_from_file)):\n",
        "        tempdf[j]['Label']=labels_from_file[j]\n",
        "        dfprova.append(tempdf[j])\n",
        "\n",
        "  return dfprova\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "KUTUNBco3tJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def list_csv_txt(folder_path):\n",
        "  '''\n",
        "  This function returns the list of csv and txt file present in the folder\n",
        "\n",
        "  Input:\n",
        "      folder_path: folder path\n",
        "  Output:\n",
        "      a list of dataframe splitted.\n",
        "  \n",
        "  '''\n",
        "  csvs= []  #container for the various csvs contained in the directory\n",
        "  df_synthetic = []  #container for temporary dataframes\n",
        "  txts=[]\n",
        "  df_synthetic_array=[]\n",
        "  print(os.listdir(folder_path))\n",
        "  # collect csv filenames and paths \n",
        "  for dirpath, dirnames, filenames in os.walk(folder_path):\n",
        "    # print(\"dirpath\", dirpath)\n",
        "    # print(\"dirnames\", dirnames)\n",
        "    filenames.sort()\n",
        "    print(\"founded\", len(filenames),\" filenames in\", dirpath)\n",
        "    \n",
        "\n",
        "    for file in filenames:\n",
        "      if len(re.findall('\\.txt', file))!=0:\n",
        "        txts.append(dirpath + '/' + file)\n",
        "      elif len(re.findall('\\.csv', file))!=0:\n",
        "        csvs.append(dirpath + '/' + file)\n",
        "      else:\n",
        "        pass\n",
        "      \n",
        "\n",
        "  # # store each dataframe in the list\n",
        "  csvs.sort()\n",
        "  txts.sort()\n",
        "  # if synthetic_standard:\n",
        "  #   csvs=csvs[:87]\n",
        "  #   txts=txts[:87] # tolgo i 20 breaths/minute che so o un macello!\n",
        "  print(f\"Founded {len(csvs)} CSV files...\")\n",
        "  print(f\"Founded {len(txts)} TXT files...\")\n",
        "  return csvs, txts"
      ],
      "metadata": {
        "id": "mkZRkJr3-VFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_frequency(txts):\n",
        "  ''' \n",
        "  this function read the frequency in the txt file provided (for example in the txt files of the generated signal)\n",
        "  '''\n",
        "  hz=0\n",
        "  with open(txts[0]) as f1:\n",
        "    lines=f1.readlines()\n",
        "  for content in lines:\n",
        "    if content.find(\"Sampling frequency\")!=-1:\n",
        "      hz = float(re.findall(\"\\d+\\.*\\d+\", content)[0])\n",
        "  return hz"
      ],
      "metadata": {
        "id": "0R7w43GcOYGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_label_recorded(path):\n",
        "  '''\n",
        "  This functions return the label of the pulse oximiter recordings\n",
        "\n",
        "  Input:\n",
        "      path: folder path\n",
        "  Output:\n",
        "      a dictionary\n",
        "  \n",
        "  '''\n",
        "  txts=[]; dfprova=[];\n",
        "  for dirpath, dirnames, filenames in os.walk(path):\n",
        "    for file in filenames:\n",
        "        txts.append(dirpath + '/' + file)\n",
        "  txts.sort()\n",
        "  label_dict={}\n",
        "  for i in range(len(txts)):\n",
        "    with open(txts[i]) as f:\n",
        "      lines = f.readlines()\n",
        "      # print(lines)\n",
        "      label_dict[i]=[0 if j=='Na\\n' else int(j) for j in lines]\n",
        "  return label_dict"
      ],
      "metadata": {
        "id": "mH6Kce_3AJSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_recorded(dfs, freq, label_dic):\n",
        "  '''\n",
        "  This functions return the data of the pulse oximiter recordings and the label\n",
        "\n",
        "  Input:\n",
        "      dfs: DataFrame\n",
        "      freq: sample rate\n",
        "      label_dic: dictionary of labels\n",
        "  Output:\n",
        "      Array, List\n",
        "  \n",
        "  '''\n",
        "  merged=0; first_time=True; recorded_array=0\n",
        "  samples_one_minute=int(np.round(freq*60))\n",
        "  y=[]\n",
        "  for i in range(len(dfs)):\n",
        "    label=True\n",
        "    listdelcaz=[]\n",
        "    print(\"-\"*60)\n",
        "    if dfs[i].shape[0]<samples_one_minute:\n",
        "      print(f\"dfs {i} too small! go further!\")\n",
        "      continue\n",
        "    list_of_dfs=split_long_record(dfs[i],freq,sec_to_split=60)\n",
        "    print(f\"Splitting dfs {i} in {len(list_of_dfs)}\")\n",
        "    for j in range(len(list_of_dfs)):\n",
        "      if i in list(label_dic.keys()):\n",
        "        y.append(label_dic[i][j])\n",
        "        df_array=np.array(list_of_dfs[j].PPGvalue)\n",
        "        listdelcaz.append(df_array[:samples_one_minute+1])\n",
        "        label=True\n",
        "      else:\n",
        "        label=False\n",
        "\n",
        "    print(\"labels\", len(y))\n",
        "    if label:\n",
        "      recorded_array=np.array( listdelcaz)\n",
        "    # recorded_array = np.reshape(recorded_array, -1)\n",
        "      print(\"recorded array\",recorded_array.shape)\n",
        "      if first_time:\n",
        "        merged=recorded_array\n",
        "        first_time=False\n",
        "      else:\n",
        "        merged = np.concatenate((merged, recorded_array), axis=0)\n",
        "    print(\"merged\", merged.shape)\n",
        "  print(\"Final Merged:\", merged.shape)\n",
        "  return merged,y\n"
      ],
      "metadata": {
        "id": "kiPPDzufA1uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_for_synthetic(file):\n",
        "  '''\n",
        "  This functions return the label of a synthetic signal\n",
        "\n",
        "  Input:\n",
        "      file: file path\n",
        "  Output:\n",
        "      Integer\n",
        "  \n",
        "  '''\n",
        "  label=0; fermitutti=False; soglia=0\n",
        "  with open(file) as f1:\n",
        "      lines=f1.readlines()\n",
        "  for content in lines:\n",
        "    if content.find(\"Simulated heart rate\")!=-1:\n",
        "      hr = int(re.findall(\"\\d+\", content)[0])\n",
        "      if hr!=80:\n",
        "        return label\n",
        "    elif content.find(\"Simulated respiratory rate\")!=-1:\n",
        "      return int(re.findall(\"\\d+\", content)[0])\n",
        "  print(f\"founded label {label}\")\n",
        "  return label"
      ],
      "metadata": {
        "id": "VtlRqqtn769W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_repeated_values(idx, txts):\n",
        "  with open(txts[idx]) as f1:\n",
        "    lines_next=f1.readlines()\n",
        "  for content_next in lines_next:\n",
        "    if content_next.find(\"Simulated respiratory rate\")!=-1:\n",
        "      rr_next = int(re.findall(\"\\d+\", content_next)[0])\n",
        "      return rr_next==20\n"
      ],
      "metadata": {
        "id": "MciVuU2u7Y2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_csv_file(csvs):\n",
        "  '''\n",
        "  This functions returns synthetic signal\n",
        "\n",
        "  Input:\n",
        "      csvs: list of csv file\n",
        "  Output:\n",
        "      list of array\n",
        "  \n",
        "  '''    \n",
        "  df_synthetic_array=[]; true_shape=0\n",
        "  # df_synthetic=[]\n",
        "  for k in range(len(csvs)):\n",
        "    dftemp=pd.read_csv(csvs[k], names=['ECG', 'PPG'],sep=',')\n",
        "    dfarray=dftemp.drop(['ECG'], axis=1).to_numpy()\n",
        "    dfarray=dfarray.reshape(-1)\n",
        "    # if i==0:\n",
        "    #   true_shape = dfarray.shape[0]\n",
        "    # df_synthetic.append(dftemp)\n",
        "    df_synthetic_array.append(dfarray) \n",
        "  return df_synthetic_array"
      ],
      "metadata": {
        "id": "u5-CTzoApEMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_datetime(df):\n",
        "  print(pd.to_datetime(df.OXYTimestamps[0], unit='ms'))\n",
        "  print(pd.to_datetime(df.OXYTimestamps[len(df.OXYTimestamps)-1], unit='ms'))\n",
        "  # print(pd.to_datetime(df.OXYTimestamps[len(df.OXYTimestamps)-1]-df.OXYTimestamps[0], unit='ms'))\n",
        "  prova=pd.to_datetime(df.OXYTimestamps[len(df.OXYTimestamps)-1]-df.OXYTimestamps[0], unit='ms')\n",
        "  print(prova)\n",
        "  # prova.strftime(\"%M:%S:%f\")\n",
        "  a_timedelta = prova - datetime.datetime(1970, 1, 1)\n",
        "  seconds = a_timedelta.total_seconds()\n",
        "\n",
        "  print(seconds)"
      ],
      "metadata": {
        "id": "wYtaU8Xv2zk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_synthetic_data(csvs, txts, df_synthetic_array):  \n",
        "  '''\n",
        "  This functions returns well formatted array of synthetic signal\n",
        "  Input:\n",
        "      csvs: ?? is used??\n",
        "      txts: txt file (in synthetic data every csv file has a txt file with the documentation)\n",
        "      df_synthetic_array: list of array\n",
        "  Output:\n",
        "      Array, Integer\n",
        "  \n",
        "  '''   \n",
        "  start_time = time. time()\n",
        "  merged=0\n",
        "  First_time=True \n",
        "  hz=get_frequency(txts)\n",
        "  samples_one_minute=int(np.round(hz*60))\n",
        "  # print(samples_one_minute)\n",
        "  average=0; temp_array=0\n",
        "  for i in range(len(df_synthetic_array)):\n",
        "    if i!=0:\n",
        "      # print(ar_to_merge.shape)\n",
        "      if merged.shape[0]%(ar_to_merge.shape[0]*20)==0:\n",
        "        print(\"what merged so far: \", merged.shape)\n",
        "    flag=True; idx_start=0; samples=[];temp_list=[]\n",
        "    while flag:\n",
        "      idx_end=int(idx_start+samples_one_minute)\n",
        "      if idx_end>df_synthetic_array[i].shape[0]-1: \n",
        "        break\n",
        "        flag=False\n",
        "      else:\n",
        "        samples.append(df_synthetic_array[i][idx_start:idx_end])\n",
        "        idx_start=idx_start+int(hz)\n",
        "    ar_to_merge=np.stack(samples, axis=0 ) #(150,30000)\n",
        "    # print(ar_to_merge.shape)\n",
        "    if First_time:\n",
        "      merged = ar_to_merge\n",
        "      First_time=False\n",
        "    else:\n",
        "      merged = np.concatenate((merged, ar_to_merge), axis=0)\n",
        "    # merged=np.stack( df_synthetic_array, axis=0 )\n",
        "\n",
        "  print(\"final merge shape\",merged.shape) \n",
        "  print(\"-\"*40)  \n",
        "  print(\"Time Execution: \")\n",
        "  print(\"--- %s seconds ---\" % np.round(time. time() - start_time,2))\n",
        "  return merged, len(samples)"
      ],
      "metadata": {
        "id": "slNJnRGBEAR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_bimdc(csvs):\n",
        "  '''\n",
        "  This functions returns well formatted array of BIMDC signal\n",
        "  Input:\n",
        "      csvs: csv file\n",
        "  Output:\n",
        "      Array\n",
        "  \n",
        "  ''' \n",
        "  df_real_array=[]; df_labels_real=[]\n",
        "  for i in range(len(csvs)): \n",
        "    if len(re.findall('\\_Signals', csvs[i]))!=0:\n",
        "      dftemp=pd.read_csv(csvs[i])\n",
        "      dfarray=dftemp[' PLETH'].to_numpy()\n",
        "      dfarray=dfarray.reshape(-1)\n",
        "      # print(dfarray.shape) \n",
        "      df_real_array.append(dfarray)\n",
        "    elif len(re.findall('\\_Numerics', csvs[i]))!=0:\n",
        "      dftemp=pd.read_csv(csvs[i])\n",
        "      # print( dftemp.head())\n",
        "      # print(dftemp.columns)\n",
        "      # dflabels=dftemp.drop(['Time [s]', 'HR', 'PULSE', 'SpO2'], axis=1).to_numpy()\n",
        "      dflabels = dftemp[['Time [s]',' RESP']]\n",
        "      # print(dflabels.shape)\n",
        "      df_labels_real.append(dflabels)\n",
        "    else:\n",
        "      continue\n",
        "  return df_real_array, df_labels_real \n",
        "\n",
        "def get_bimdc(list_array_bimdc):\n",
        "  idx_start=0\n",
        "  merged=np.ones(shape=(1,1))\n",
        "  for i in range(len(list_array_bimdc)):\n",
        "    j=0; df_splitted=[]\n",
        "    while (j+7500)<list_array_bimdc[i].shape[0]:\n",
        "      temp = list_array_bimdc[i][j:j+7500]\n",
        "      j=j+7500\n",
        "      f = signal.resample(temp, 5801)\n",
        "      # print(f.shape)\n",
        "      df_splitted.append(f)\n",
        "\n",
        "\n",
        "    prova=np.array(df_splitted)\n",
        "    # print(prova.shape)\n",
        "    if merged.shape==(1,1):\n",
        "      merged=prova\n",
        "    else:\n",
        "      merged = np.concatenate((merged, prova), axis=0)\n",
        "  return merged\n",
        "\n",
        "def get_bimdc_label(list_label_bimdc):\n",
        "  '''\n",
        "  This function returns labels  of BIMDC signal\n",
        "  Input:\n",
        "      list_label_bimdc: list\n",
        "  Output:\n",
        "      Array, List\n",
        "  \n",
        "  ''' \n",
        "  labels_real=[]\n",
        "  for i in range(len(list_label_bimdc)):\n",
        "    for j in range(1,9):\n",
        "      labels_real.append(list_label_bimdc[i].iloc[60*j,1])\n",
        "  indices = [i for i, x in enumerate(labels_real) if x != 0 and pd.isna(x)==False]\n",
        "  labels_real = [int(labels_real[index]) for index in indices]\n",
        "  return labels_real, indices\n",
        " \n"
      ],
      "metadata": {
        "id": "65W31fxjd83b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading real data and preparing data structure"
      ],
      "metadata": {
        "id": "x1x6s9U60jFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the files"
      ],
      "metadata": {
        "id": "KDfNb1ZUeE-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path_syn_ar02= \"/content/drive/MyDrive/HDA project/Synthetic Data/rrest-syn_csv_ar_02\"\n",
        "folder_path_syn_ar03= \"/content/drive/MyDrive/HDA project/Synthetic Data/rrest-syn_csv_ar_03\"\n",
        "folder_path_syn_ar04= \"/content/drive/MyDrive/HDA project/Synthetic Data/rrest-syn_csv_ar_04\"\n",
        "folder_path_syn_arfm_3= \"/content/drive/MyDrive/HDA project/Synthetic Data/rrest-syn_csv_arfm_3\"\n",
        "folder_path_syn_arfm_4= \"/content/drive/MyDrive/HDA project/Synthetic Data/rrest-syn_csv_arfm_4\"\n",
        "folder_path_syn_sig_range_3= \"/content/drive/MyDrive/HDA project/Synthetic Data/rrest-syn_csv_sig_range_3\"\n",
        "folder_path_syn_sig_range_6= \"/content/drive/MyDrive/HDA project/Synthetic Data/rrest-syn_csv_sig_range_6\"\n",
        "folder_path_syn_sig_range_9= \"/content/drive/MyDrive/HDA project/Synthetic Data/rrest-syn_csv_sig_range_9\"\n",
        "\n",
        "folder_path_little = \"/content/drive/MyDrive/HDA project/Synthetic Data/rrest-syn_csv_modified_hz\"\n",
        "folder_path_real = '/content/drive/MyDrive/HDA project/Synthetic Data/BIMDC'\n",
        "\n",
        "csvs_syn, txts_syn= list_csv_txt(folder_path_little)\n",
        "csvs_syn_ar02, txts_syn_ar02= list_csv_txt(folder_path_syn_ar02)\n",
        "csvs_syn_ar03, txts_syn_ar03= list_csv_txt(folder_path_syn_ar03)\n",
        "csvs_syn_ar04, txts_syn_ar04= list_csv_txt(folder_path_syn_ar04)\n",
        "\n",
        "csvs_syn_arfm3, txts_syn_arfm3= list_csv_txt(folder_path_syn_arfm_3)\n",
        "csvs_syn_arfm4, txts_syn_arfm4= list_csv_txt(folder_path_syn_arfm_4)\n",
        "\n",
        "csvs_syn_range3, txts_syn_range3= list_csv_txt(folder_path_syn_sig_range_3)\n",
        "csvs_syn_range6, txts_syn_range6= list_csv_txt(folder_path_syn_sig_range_6)\n",
        "csvs_syn_range9, txts_syn_range9= list_csv_txt(folder_path_syn_sig_range_9)\n",
        "\n",
        "# csvs_syn_range6, txts_syn_range6= list_csv_txt(folder_path_syn_sig_range_6)\n",
        "\n",
        "csvs_real, txts_real= list_csv_txt(folder_path_real)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcU3Z2gnTVhU",
        "outputId": "308595f2-8064-45a6-8269-4c3b6ffcc0a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['rrest-syn011_fix.txt', 'rrest-syn084_data.csv', 'rrest-syn041_data.csv', 'rrest-syn055_data.csv', 'rrest-syn035_data.csv', 'rrest-syn057_data.csv', 'rrest-syn012_data.csv', 'rrest-syn080_fix.txt', 'rrest-syn043_fix.txt', 'rrest-syn049_fix.txt', 'rrest-syn026_data.csv', 'rrest-syn009_fix.txt', 'rrest-syn071_data.csv', 'rrest-syn047_data.csv', 'rrest-syn078_fix.txt', 'rrest-syn084_fix.txt', 'rrest-syn018_data.csv', 'rrest-syn077_fix.txt', 'rrest-syn001_data.csv', 'rrest-syn028_data.csv', 'rrest-syn023_fix.txt', 'rrest-syn030_fix.txt', 'rrest-syn087_data.csv', 'rrest-syn040_fix.txt', 'rrest-syn034_data.csv', 'rrest-syn079_data.csv', 'rrest-syn013_fix.txt', 'rrest-syn036_fix.txt', 'rrest-syn027_fix.txt', 'rrest-syn069_data.csv', 'rrest-syn050_data.csv', 'rrest-syn072_data.csv', 'rrest-syn019_data.csv', 'rrest-syn004_data.csv', 'rrest-syn032_data.csv', 'rrest-syn010_data.csv', 'rrest-syn070_fix.txt', 'rrest-syn069_fix.txt', 'rrest-syn056_fix.txt', 'rrest-syn044_fix.txt', 'rrest-syn037_fix.txt', 'rrest-syn060_fix.txt', 'rrest-syn017_fix.txt', 'rrest-syn082_data.csv', 'rrest-syn040_data.csv', 'rrest-syn086_data.csv', 'rrest-syn071_fix.txt', 'rrest-syn038_fix.txt', 'rrest-syn033_fix.txt', 'rrest-syn014_data.csv', 'rrest-syn070_data.csv', 'rrest-syn015_fix.txt', 'rrest-syn075_fix.txt', 'rrest-syn046_data.csv', 'rrest-syn033_data.csv', 'rrest-syn058_data.csv', 'rrest-syn085_fix.txt', 'rrest-syn031_fix.txt', 'rrest-syn076_fix.txt', 'rrest-syn067_data.csv', 'rrest-syn052_data.csv', 'rrest-syn083_data.csv', 'rrest-syn030_data.csv', 'rrest-syn060_data.csv', 'rrest-syn055_fix.txt', 'rrest-syn008_data.csv', 'rrest-syn062_fix.txt', 'rrest-syn035_fix.txt', 'rrest-syn074_data.csv', 'rrest-syn039_fix.txt', 'rrest-syn024_fix.txt', 'rrest-syn064_data.csv', 'rrest-syn076_data.csv', 'rrest-syn032_fix.txt', 'rrest-syn086_fix.txt', 'rrest-syn005_data.csv', 'rrest-syn049_data.csv', 'rrest-syn006_fix.txt', 'rrest-syn038_data.csv', 'rrest-syn018_fix.txt', 'rrest-syn015_data.csv', 'rrest-syn074_fix.txt', 'rrest-syn056_data.csv', 'rrest-syn003_fix.txt', 'rrest-syn081_fix.txt', 'rrest-syn048_fix.txt', 'rrest-syn068_fix.txt', 'rrest-syn014_fix.txt', 'rrest-syn016_data.csv', 'rrest-syn003_data.csv', 'rrest-syn022_fix.txt', 'rrest-syn025_data.csv', 'rrest-syn021_fix.txt', 'rrest-syn013_data.csv', 'rrest-syn024_data.csv', 'rrest-syn054_fix.txt', 'rrest-syn087_fix.txt', 'rrest-syn073_data.csv', 'rrest-syn006_data.csv', 'rrest-syn037_data.csv', 'rrest-syn066_data.csv', 'rrest-syn020_fix.txt', 'rrest-syn005_fix.txt', 'rrest-syn081_data.csv', 'rrest-syn059_fix.txt', 'rrest-syn012_fix.txt', 'rrest-syn002_fix.txt', 'rrest-syn007_data.csv', 'rrest-syn019_fix.txt', 'rrest-syn068_data.csv', 'rrest-syn010_fix.txt', 'rrest-syn001_fix.txt', 'rrest-syn052_fix.txt', 'rrest-syn011_data.csv', 'rrest-syn039_data.csv', 'rrest-syn042_fix.txt', 'rrest-syn063_data.csv', 'rrest-syn026_fix.txt', 'rrest-syn029_fix.txt', 'rrest-syn004_fix.txt', 'rrest-syn036_data.csv', 'rrest-syn064_fix.txt', 'rrest-syn008_fix.txt', 'rrest-syn047_fix.txt', 'rrest-syn022_data.csv', 'rrest-syn085_data.csv', 'rrest-syn002_data.csv', 'rrest-syn050_fix.txt', 'rrest-syn063_fix.txt', 'rrest-syn034_fix.txt', 'rrest-syn079_fix.txt', 'rrest-syn059_data.csv', 'rrest-syn051_fix.txt', 'rrest-syn072_fix.txt', 'rrest-syn054_data.csv', 'rrest-syn023_data.csv', 'rrest-syn073_fix.txt', 'rrest-syn007_fix.txt', 'rrest-syn053_data.csv', 'rrest-syn025_fix.txt', 'rrest-syn061_data.csv', 'rrest-syn017_data.csv', 'rrest-syn043_data.csv', 'rrest-syn066_fix.txt', 'rrest-syn067_fix.txt', 'rrest-syn053_fix.txt', 'rrest-syn061_fix.txt', 'rrest-syn042_data.csv', 'rrest-syn083_fix.txt', 'rrest-syn048_data.csv', 'rrest-syn046_fix.txt', 'rrest-syn080_data.csv', 'rrest-syn031_data.csv', 'rrest-syn029_data.csv', 'rrest-syn065_data.csv', 'rrest-syn045_fix.txt', 'rrest-syn077_data.csv', 'rrest-syn082_fix.txt', 'rrest-syn020_data.csv', 'rrest-syn044_data.csv', 'rrest-syn057_fix.txt', 'rrest-syn045_data.csv', 'rrest-syn058_fix.txt', 'rrest-syn051_data.csv', 'rrest-syn027_data.csv', 'rrest-syn021_data.csv', 'rrest-syn028_fix.txt', 'rrest-syn065_fix.txt', 'rrest-syn009_data.csv', 'rrest-syn078_data.csv', 'rrest-syn075_data.csv', 'rrest-syn016_fix.txt', 'rrest-syn041_fix.txt', 'rrest-syn062_data.csv']\n",
            "founded 174  filenames in /content/drive/MyDrive/HDA project/Synthetic Data/rrest-syn_csv_modified_hz\n",
            "Founded 87 CSV files...\n",
            "Founded 87 TXT files...\n",
            "['rrest-syn135_data.csv', 'rrest-syn143_data.csv', 'rrest-syn076_data.csv', 'rrest-syn130_fix.txt', 'rrest-syn133_data.csv', 'rrest-syn027_data.csv', 'rrest-syn101_fix.txt', 'rrest-syn069_data.csv', 'rrest-syn124_fix.txt', 'rrest-syn137_fix.txt', 'rrest-syn073_fix.txt', 'rrest-syn040_data.csv', 'rrest-syn043_data.csv', 'rrest-syn087_fix.txt', 'rrest-syn046_data.csv', 'rrest-syn113_fix.txt', 'rrest-syn165_data.csv', 'rrest-syn174_fix.txt', 'rrest-syn194_data.csv', 'rrest-syn151_fix.txt', 'rrest-syn161_fix.txt', 'rrest-syn028_data.csv', 'rrest-syn002_data.csv', 'rrest-syn181_fix.txt', 'rrest-syn193_data.csv', 'rrest-syn066_fix.txt', 'rrest-syn001_fix.txt', 'rrest-syn002_fix.txt', 'rrest-syn088_data.csv', 'rrest-syn167_fix.txt', 'rrest-syn178_fix.txt', 'rrest-syn106_fix.txt', 'rrest-syn026_data.csv', 'rrest-syn169_fix.txt', 'rrest-syn020_fix.txt', 'rrest-syn006_fix.txt', 'rrest-syn018_data.csv', 'rrest-syn091_data.csv', 'rrest-syn171_data.csv', 'rrest-syn132_data.csv', 'rrest-syn081_data.csv', 'rrest-syn166_fix.txt', 'rrest-syn193_fix.txt', 'rrest-syn161_data.csv', 'rrest-syn063_data.csv', 'rrest-syn201_fix.txt', 'rrest-syn093_data.csv', 'rrest-syn074_data.csv', 'rrest-syn125_data.csv', 'rrest-syn014_data.csv', 'rrest-syn033_data.csv', 'rrest-syn101_data.csv', 'rrest-syn180_fix.txt', 'rrest-syn114_data.csv', 'rrest-syn047_data.csv', 'rrest-syn069_fix.txt', 'rrest-syn080_fix.txt', 'rrest-syn100_fix.txt', 'rrest-syn048_fix.txt', 'rrest-syn068_data.csv', 'rrest-syn075_fix.txt', 'rrest-syn102_data.csv', 'rrest-syn074_fix.txt', 'rrest-syn153_data.csv', 'rrest-syn097_fix.txt', 'rrest-syn067_fix.txt', 'rrest-syn191_fix.txt', 'rrest-syn186_data.csv', 'rrest-syn023_data.csv', 'rrest-syn154_fix.txt', 'rrest-syn038_data.csv', 'rrest-syn039_data.csv', 'rrest-syn107_data.csv', 'rrest-syn083_data.csv', 'rrest-syn111_fix.txt', 'rrest-syn034_fix.txt', 'rrest-syn044_fix.txt', 'rrest-syn037_data.csv', 'rrest-syn192_fix.txt', 'rrest-syn199_fix.txt', 'rrest-syn189_data.csv', 'rrest-syn015_data.csv', 'rrest-syn152_fix.txt', 'rrest-syn152_data.csv', 'rrest-syn150_fix.txt', 'rrest-syn030_data.csv', 'rrest-syn173_fix.txt', 'rrest-syn070_data.csv', 'rrest-syn180_data.csv', 'rrest-syn125_fix.txt', 'rrest-syn166_data.csv', 'rrest-syn013_fix.txt', 'rrest-syn143_fix.txt', 'rrest-syn102_fix.txt', 'rrest-syn157_fix.txt', 'rrest-syn172_fix.txt', 'rrest-syn092_data.csv', 'rrest-syn107_fix.txt', 'rrest-syn094_data.csv', 'rrest-syn027_fix.txt', 'rrest-syn092_fix.txt', 'rrest-syn098_fix.txt', 'rrest-syn063_fix.txt', 'rrest-syn042_fix.txt', 'rrest-syn055_fix.txt', 'rrest-syn011_fix.txt', 'rrest-syn005_data.csv', 'rrest-syn100_data.csv', 'rrest-syn022_data.csv', 'rrest-syn079_fix.txt', 'rrest-syn053_data.csv', 'rrest-syn066_data.csv', 'rrest-syn090_fix.txt', 'rrest-syn008_data.csv', 'rrest-syn087_data.csv', 'rrest-syn185_fix.txt', 'rrest-syn184_fix.txt', 'rrest-syn084_data.csv', 'rrest-syn096_data.csv', 'rrest-syn040_fix.txt', 'rrest-syn117_data.csv', 'rrest-syn105_data.csv', 'rrest-syn189_fix.txt', 'rrest-syn073_data.csv', 'rrest-syn089_data.csv', 'rrest-syn084_fix.txt', 'rrest-syn065_data.csv', 'rrest-syn148_data.csv', 'rrest-syn196_fix.txt', 'rrest-syn175_fix.txt', 'rrest-syn114_fix.txt', 'rrest-syn019_fix.txt', 'rrest-syn132_fix.txt', 'rrest-syn156_fix.txt', 'rrest-syn025_data.csv', 'rrest-syn049_fix.txt', 'rrest-syn031_fix.txt', 'rrest-syn124_data.csv', 'rrest-syn067_data.csv', 'rrest-syn112_fix.txt', 'rrest-syn086_fix.txt', 'rrest-syn178_data.csv', 'rrest-syn136_fix.txt', 'rrest-syn118_fix.txt', 'rrest-syn121_data.csv', 'rrest-syn056_data.csv', 'rrest-syn059_data.csv', 'rrest-syn138_data.csv', 'rrest-syn060_fix.txt', 'rrest-syn196_data.csv', 'rrest-syn025_fix.txt', 'rrest-syn018_fix.txt', 'rrest-syn052_fix.txt', 'rrest-syn135_fix.txt', 'rrest-syn140_data.csv', 'rrest-syn035_data.csv', 'rrest-syn001_data.csv', 'rrest-syn128_fix.txt', 'rrest-syn071_data.csv', 'rrest-syn168_fix.txt', 'rrest-syn111_data.csv', 'rrest-syn190_fix.txt', 'rrest-syn112_data.csv', 'rrest-syn079_data.csv', 'rrest-syn179_fix.txt', 'rrest-syn068_fix.txt', 'rrest-syn120_data.csv', 'rrest-syn162_fix.txt', 'rrest-syn199_data.csv', 'rrest-syn064_data.csv', 'rrest-syn155_data.csv', 'rrest-syn181_data.csv', 'rrest-syn036_data.csv', 'rrest-syn056_fix.txt', 'rrest-syn008_fix.txt', 'rrest-syn131_fix.txt', 'rrest-syn051_data.csv', 'rrest-syn085_fix.txt', 'rrest-syn179_data.csv', 'rrest-syn168_data.csv', 'rrest-syn012_fix.txt', 'rrest-syn149_fix.txt', 'rrest-syn032_fix.txt', 'rrest-syn050_data.csv', 'rrest-syn038_fix.txt', 'rrest-syn160_data.csv', 'rrest-syn019_data.csv', 'rrest-syn158_data.csv', 'rrest-syn162_data.csv', 'rrest-syn010_data.csv', 'rrest-syn110_data.csv', 'rrest-syn095_data.csv', 'rrest-syn140_fix.txt', 'rrest-syn142_data.csv', 'rrest-syn037_fix.txt', 'rrest-syn024_fix.txt', 'rrest-syn104_data.csv', 'rrest-syn062_fix.txt', 'rrest-syn097_data.csv', 'rrest-syn091_fix.txt', 'rrest-syn070_fix.txt', 'rrest-syn109_data.csv', 'rrest-syn198_data.csv', 'rrest-syn173_data.csv', 'rrest-syn155_fix.txt', 'rrest-syn042_data.csv', 'rrest-syn144_fix.txt', 'rrest-syn007_data.csv', 'rrest-syn183_data.csv', 'rrest-syn117_fix.txt', 'rrest-syn190_data.csv', 'rrest-syn045_fix.txt', 'rrest-syn186_fix.txt', 'rrest-syn007_fix.txt', 'rrest-syn048_data.csv', 'rrest-syn005_fix.txt', 'rrest-syn055_data.csv', 'rrest-syn145_data.csv', 'rrest-syn021_fix.txt', 'rrest-syn050_fix.txt', 'rrest-syn170_data.csv', 'rrest-syn012_data.csv', 'rrest-syn137_data.csv', 'rrest-syn026_fix.txt', 'rrest-syn138_fix.txt', 'rrest-syn197_fix.txt', 'rrest-syn081_fix.txt', 'rrest-syn089_fix.txt', 'rrest-syn198_fix.txt', 'rrest-syn016_data.csv', 'rrest-syn109_fix.txt', 'rrest-syn165_fix.txt', 'rrest-syn098_data.csv', 'rrest-syn176_data.csv', 'rrest-syn054_fix.txt', 'rrest-syn120_fix.txt', 'rrest-syn082_data.csv', 'rrest-syn022_fix.txt', 'rrest-syn160_fix.txt', 'rrest-syn131_data.csv', 'rrest-syn128_data.csv', 'rrest-syn197_data.csv', 'rrest-syn030_fix.txt', 'rrest-syn035_fix.txt', 'rrest-syn014_fix.txt', 'rrest-syn054_data.csv', 'rrest-syn116_data.csv', 'rrest-syn105_fix.txt', 'rrest-syn194_fix.txt', 'rrest-syn106_data.csv', 'rrest-syn083_fix.txt', 'rrest-syn200_data.csv', 'rrest-syn167_data.csv', 'rrest-syn126_data.csv', 'rrest-syn036_fix.txt', 'rrest-syn187_data.csv', 'rrest-syn080_data.csv', 'rrest-syn184_data.csv', 'rrest-syn144_data.csv', 'rrest-syn072_data.csv', 'rrest-syn010_fix.txt', 'rrest-syn071_fix.txt', 'rrest-syn187_fix.txt', 'rrest-syn078_data.csv', 'rrest-syn149_data.csv', 'rrest-syn163_data.csv', 'rrest-syn185_data.csv', 'rrest-syn150_data.csv', 'rrest-syn047_fix.txt', 'rrest-syn141_data.csv', 'rrest-syn130_data.csv', 'rrest-syn077_fix.txt', 'rrest-syn183_fix.txt', 'rrest-syn171_fix.txt', 'rrest-syn110_fix.txt', 'rrest-syn029_fix.txt', 'rrest-syn156_data.csv', 'rrest-syn170_fix.txt', 'rrest-syn034_data.csv', 'rrest-syn044_data.csv', 'rrest-syn188_data.csv', 'rrest-syn029_data.csv', 'rrest-syn127_fix.txt', 'rrest-syn129_data.csv', 'rrest-syn065_fix.txt', 'rrest-syn182_fix.txt', 'rrest-syn095_fix.txt', 'rrest-syn006_data.csv', 'rrest-syn076_fix.txt', 'rrest-syn122_fix.txt', 'rrest-syn148_fix.txt', 'rrest-syn090_data.csv', 'rrest-syn127_data.csv', 'rrest-syn075_data.csv', 'rrest-syn064_fix.txt', 'rrest-syn045_data.csv', 'rrest-syn024_data.csv', 'rrest-syn118_data.csv', 'rrest-syn139_fix.txt', 'rrest-syn145_fix.txt', 'rrest-syn003_fix.txt', 'rrest-syn103_fix.txt', 'rrest-syn053_fix.txt', 'rrest-syn191_data.csv', 'rrest-syn003_data.csv', 'rrest-syn058_data.csv', 'rrest-syn032_data.csv', 'rrest-syn020_data.csv', 'rrest-syn147_data.csv', 'rrest-syn061_data.csv', 'rrest-syn142_fix.txt', 'rrest-syn096_fix.txt', 'rrest-syn093_fix.txt', 'rrest-syn133_fix.txt', 'rrest-syn116_fix.txt', 'rrest-syn192_data.csv', 'rrest-syn058_fix.txt', 'rrest-syn023_fix.txt', 'rrest-syn177_data.csv', 'rrest-syn057_fix.txt', 'rrest-syn195_fix.txt', 'rrest-syn182_data.csv', 'rrest-syn078_fix.txt', 'rrest-syn123_fix.txt', 'rrest-syn113_data.csv', 'rrest-syn094_fix.txt', 'rrest-syn151_data.csv', 'rrest-syn177_fix.txt', 'rrest-syn154_data.csv', 'rrest-syn157_data.csv', 'rrest-syn200_fix.txt', 'rrest-syn062_data.csv', 'rrest-syn099_data.csv', 'rrest-syn104_fix.txt', 'rrest-syn049_data.csv', 'rrest-syn004_data.csv', 'rrest-syn195_data.csv', 'rrest-syn099_fix.txt', 'rrest-syn041_fix.txt', 'rrest-syn163_fix.txt', 'rrest-syn153_fix.txt', 'rrest-syn004_fix.txt', 'rrest-syn122_data.csv', 'rrest-syn033_fix.txt', 'rrest-syn016_fix.txt', 'rrest-syn129_fix.txt', 'rrest-syn009_data.csv', 'rrest-syn011_data.csv', 'rrest-syn077_data.csv', 'rrest-syn134_fix.txt', 'rrest-syn088_fix.txt', 'rrest-syn060_data.csv', 'rrest-syn031_data.csv', 'rrest-syn134_data.csv', 'rrest-syn123_data.csv', 'rrest-syn021_data.csv', 'rrest-syn043_fix.txt', 'rrest-syn164_data.csv', 'rrest-syn051_fix.txt', 'rrest-syn082_fix.txt', 'rrest-syn176_fix.txt', 'rrest-syn121_fix.txt', 'rrest-syn146_fix.txt', 'rrest-syn108_data.csv', 'rrest-syn017_data.csv', 'rrest-syn119_fix.txt', 'rrest-syn015_fix.txt', 'rrest-syn028_fix.txt', 'rrest-syn164_fix.txt', 'rrest-syn159_data.csv', 'rrest-syn115_fix.txt', 'rrest-syn103_data.csv', 'rrest-syn108_fix.txt', 'rrest-syn061_fix.txt', 'rrest-syn172_data.csv', 'rrest-syn119_data.csv', 'rrest-syn136_data.csv', 'rrest-syn057_data.csv', 'rrest-syn158_fix.txt', 'rrest-syn046_fix.txt', 'rrest-syn017_fix.txt', 'rrest-syn085_data.csv', 'rrest-syn141_fix.txt', 'rrest-syn147_fix.txt', 'rrest-syn013_data.csv', 'rrest-syn159_fix.txt', 'rrest-syn009_fix.txt', 'rrest-syn174_data.csv', 'rrest-syn126_fix.txt', 'rrest-syn139_data.csv', 'rrest-syn052_data.csv', 'rrest-syn086_data.csv', 'rrest-syn041_data.csv', 'rrest-syn072_fix.txt', 'rrest-syn201_data.csv', 'rrest-syn175_data.csv', 'rrest-syn039_fix.txt', 'rrest-syn169_data.csv', 'rrest-syn188_fix.txt', 'rrest-syn059_fix.txt', 'rrest-syn115_data.csv', 'rrest-syn146_data.csv']\n",
            "founded 402  filenames in /content/drive/MyDrive/HDA project/Synthetic Data/rrest-syn_csv_ar_02\n",
            "Founded 201 CSV files...\n",
            "Founded 201 TXT files...\n",
            "['rrest-syn_csv']\n",
            "founded 0  filenames in /content/drive/MyDrive/HDA project/Synthetic Data/rrest-syn_csv_ar_03\n",
            "founded 402  filenames in /content/drive/MyDrive/HDA project/Synthetic Data/rrest-syn_csv_ar_03/rrest-syn_csv\n",
            "Founded 201 CSV files...\n",
            "Founded 201 TXT files...\n",
            "['rrest-syn_csv']\n",
            "founded 0  filenames in /content/drive/MyDrive/HDA project/Synthetic Data/rrest-syn_csv_ar_04\n",
            "founded 372  filenames in /content/drive/MyDrive/HDA project/Synthetic Data/rrest-syn_csv_ar_04/rrest-syn_csv\n",
            "Founded 186 CSV files...\n",
            "Founded 186 TXT files...\n",
            "['rrest-syn026_data.csv', 'rrest-syn076_data.csv', 'rrest-syn047_data.csv', 'rrest-syn175_fix.txt', 'rrest-syn135_fix.txt', 'rrest-syn168_data.csv', 'rrest-syn094_fix.txt', 'rrest-syn166_data.csv', 'rrest-syn149_data.csv', 'rrest-syn105_fix.txt', 'rrest-syn170_fix.txt', 'rrest-syn169_fix.txt', 'rrest-syn014_data.csv', 'rrest-syn134_data.csv', 'rrest-syn019_fix.txt', 'rrest-syn040_fix.txt', 'rrest-syn055_fix.txt', 'rrest-syn008_fix.txt', 'rrest-syn038_fix.txt', 'rrest-syn031_data.csv', 'rrest-syn023_data.csv', 'rrest-syn180_data.csv', 'rrest-syn020_data.csv', 'rrest-syn030_fix.txt', 'rrest-syn089_fix.txt', 'rrest-syn147_fix.txt', 'rrest-syn003_fix.txt', 'rrest-syn051_data.csv', 'rrest-syn093_fix.txt', 'rrest-syn017_data.csv', 'rrest-syn056_fix.txt', 'rrest-syn184_fix.txt', 'rrest-syn065_data.csv', 'rrest-syn013_data.csv', 'rrest-syn057_data.csv', 'rrest-syn049_data.csv', 'rrest-syn055_data.csv', 'rrest-syn122_data.csv', 'rrest-syn110_data.csv', 'rrest-syn127_data.csv', 'rrest-syn117_fix.txt', 'rrest-syn156_fix.txt', 'rrest-syn057_fix.txt', 'rrest-syn061_fix.txt', 'rrest-syn100_data.csv', 'rrest-syn178_fix.txt', 'rrest-syn102_data.csv', 'rrest-syn124_data.csv', 'rrest-syn035_data.csv', 'rrest-syn154_fix.txt', 'rrest-syn079_fix.txt', 'rrest-syn070_data.csv', 'rrest-syn068_data.csv', 'rrest-syn114_fix.txt', 'rrest-syn121_data.csv', 'rrest-syn093_data.csv', 'rrest-syn123_fix.txt', 'rrest-syn126_data.csv', 'rrest-syn145_fix.txt', 'rrest-syn077_data.csv', 'rrest-syn046_data.csv', 'rrest-syn125_data.csv', 'rrest-syn027_fix.txt', 'rrest-syn081_fix.txt', 'rrest-syn045_data.csv', 'rrest-syn133_fix.txt', 'rrest-syn043_fix.txt', 'rrest-syn166_fix.txt', 'rrest-syn022_fix.txt', 'rrest-syn140_data.csv', 'rrest-syn085_fix.txt', 'rrest-syn128_fix.txt', 'rrest-syn126_fix.txt', 'rrest-syn018_data.csv', 'rrest-syn017_fix.txt', 'rrest-syn003_data.csv', 'rrest-syn124_fix.txt', 'rrest-syn181_fix.txt', 'rrest-syn014_fix.txt', 'rrest-syn007_data.csv', 'rrest-syn019_data.csv', 'rrest-syn095_data.csv', 'rrest-syn102_fix.txt', 'rrest-syn031_fix.txt', 'rrest-syn181_data.csv', 'rrest-syn035_fix.txt', 'rrest-syn142_fix.txt', 'rrest-syn044_fix.txt', 'rrest-syn029_data.csv', 'rrest-syn063_fix.txt', 'rrest-syn052_fix.txt', 'rrest-syn069_fix.txt', 'rrest-syn024_fix.txt', 'rrest-syn036_fix.txt', 'rrest-syn121_fix.txt', 'rrest-syn138_fix.txt', 'rrest-syn027_data.csv', 'rrest-syn152_fix.txt', 'rrest-syn071_fix.txt', 'rrest-syn101_data.csv', 'rrest-syn051_fix.txt', 'rrest-syn089_data.csv', 'rrest-syn054_data.csv', 'rrest-syn140_fix.txt', 'rrest-syn109_fix.txt', 'rrest-syn053_fix.txt', 'rrest-syn064_data.csv', 'rrest-syn108_data.csv', 'rrest-syn131_data.csv', 'rrest-syn118_fix.txt', 'rrest-syn091_fix.txt', 'rrest-syn172_data.csv', 'rrest-syn039_fix.txt', 'rrest-syn090_fix.txt', 'rrest-syn010_data.csv', 'rrest-syn177_data.csv', 'rrest-syn083_data.csv', 'rrest-syn143_data.csv', 'rrest-syn130_data.csv', 'rrest-syn105_data.csv', 'rrest-syn127_fix.txt', 'rrest-syn120_data.csv', 'rrest-syn099_fix.txt', 'rrest-syn002_fix.txt', 'rrest-syn073_fix.txt', 'rrest-syn030_data.csv', 'rrest-syn151_fix.txt', 'rrest-syn137_fix.txt', 'rrest-syn161_data.csv', 'rrest-syn176_data.csv', 'rrest-syn153_data.csv', 'rrest-syn025_fix.txt', 'rrest-syn063_data.csv', 'rrest-syn175_data.csv', 'rrest-syn143_fix.txt', 'rrest-syn082_data.csv', 'rrest-syn088_data.csv', 'rrest-syn171_data.csv', 'rrest-syn111_fix.txt', 'rrest-syn042_data.csv', 'rrest-syn106_data.csv', 'rrest-syn060_data.csv', 'rrest-syn033_fix.txt', 'rrest-syn073_data.csv', 'rrest-syn098_fix.txt', 'rrest-syn037_data.csv', 'rrest-syn021_fix.txt', 'rrest-syn138_data.csv', 'rrest-syn171_fix.txt', 'rrest-syn058_data.csv', 'rrest-syn133_data.csv', 'rrest-syn029_fix.txt', 'rrest-syn086_data.csv', 'rrest-syn091_data.csv', 'rrest-syn006_fix.txt', 'rrest-syn096_fix.txt', 'rrest-syn047_fix.txt', 'rrest-syn106_fix.txt', 'rrest-syn036_data.csv', 'rrest-syn082_fix.txt', 'rrest-syn005_fix.txt', 'rrest-syn012_fix.txt', 'rrest-syn165_data.csv', 'rrest-syn130_fix.txt', 'rrest-syn040_data.csv', 'rrest-syn172_fix.txt', 'rrest-syn169_data.csv', 'rrest-syn162_fix.txt', 'rrest-syn129_fix.txt', 'rrest-syn092_data.csv', 'rrest-syn099_data.csv', 'rrest-syn042_fix.txt', 'rrest-syn087_fix.txt', 'rrest-syn032_data.csv', 'rrest-syn148_fix.txt', 'rrest-syn112_data.csv', 'rrest-syn067_data.csv', 'rrest-syn048_fix.txt', 'rrest-syn028_data.csv', 'rrest-syn096_data.csv', 'rrest-syn072_fix.txt', 'rrest-syn011_fix.txt', 'rrest-syn098_data.csv', 'rrest-syn107_data.csv', 'rrest-syn184_data.csv', 'rrest-syn034_fix.txt', 'rrest-syn147_data.csv', 'rrest-syn022_data.csv', 'rrest-syn137_data.csv', 'rrest-syn150_data.csv', 'rrest-syn079_data.csv', 'rrest-syn075_fix.txt', 'rrest-syn120_fix.txt', 'rrest-syn012_data.csv', 'rrest-syn054_fix.txt', 'rrest-syn168_fix.txt', 'rrest-syn060_fix.txt', 'rrest-syn160_fix.txt', 'rrest-syn161_fix.txt', 'rrest-syn128_data.csv', 'rrest-syn078_fix.txt', 'rrest-syn061_data.csv', 'rrest-syn159_fix.txt', 'rrest-syn162_data.csv', 'rrest-syn119_data.csv', 'rrest-syn085_data.csv', 'rrest-syn039_data.csv', 'rrest-syn066_fix.txt', 'rrest-syn157_fix.txt', 'rrest-syn070_fix.txt', 'rrest-syn115_data.csv', 'rrest-syn064_fix.txt', 'rrest-syn156_data.csv', 'rrest-syn015_fix.txt', 'rrest-syn100_fix.txt', 'rrest-syn004_data.csv', 'rrest-syn154_data.csv', 'rrest-syn178_data.csv', 'rrest-syn135_data.csv', 'rrest-syn045_fix.txt', 'rrest-syn132_fix.txt', 'rrest-syn108_fix.txt', 'rrest-syn159_data.csv', 'rrest-syn084_fix.txt', 'rrest-syn048_data.csv', 'rrest-syn163_fix.txt', 'rrest-syn050_data.csv', 'rrest-syn109_data.csv', 'rrest-syn001_data.csv', 'rrest-syn119_fix.txt', 'rrest-syn144_data.csv', 'rrest-syn163_data.csv', 'rrest-syn118_data.csv', 'rrest-syn074_data.csv', 'rrest-syn179_data.csv', 'rrest-syn084_data.csv', 'rrest-syn023_fix.txt', 'rrest-syn146_data.csv', 'rrest-syn059_data.csv', 'rrest-syn132_data.csv', 'rrest-syn113_data.csv', 'rrest-syn167_data.csv', 'rrest-syn145_data.csv', 'rrest-syn141_data.csv', 'rrest-syn116_data.csv', 'rrest-syn150_fix.txt', 'rrest-syn115_fix.txt', 'rrest-syn103_data.csv', 'rrest-syn002_data.csv', 'rrest-syn104_data.csv', 'rrest-syn086_fix.txt', 'rrest-syn071_data.csv', 'rrest-syn015_data.csv', 'rrest-syn041_data.csv', 'rrest-syn144_fix.txt', 'rrest-syn186_data.csv', 'rrest-syn185_data.csv', 'rrest-syn008_data.csv', 'rrest-syn146_fix.txt', 'rrest-syn001_fix.txt', 'rrest-syn011_data.csv', 'rrest-syn157_data.csv', 'rrest-syn006_data.csv', 'rrest-syn025_data.csv', 'rrest-syn009_data.csv', 'rrest-syn087_data.csv', 'rrest-syn141_fix.txt', 'rrest-syn139_fix.txt', 'rrest-syn080_fix.txt', 'rrest-syn092_fix.txt', 'rrest-syn037_fix.txt', 'rrest-syn049_fix.txt', 'rrest-syn083_fix.txt', 'rrest-syn094_data.csv', 'rrest-syn114_data.csv', 'rrest-syn186_fix.txt', 'rrest-syn183_fix.txt', 'rrest-syn116_fix.txt', 'rrest-syn152_data.csv', 'rrest-syn059_fix.txt', 'rrest-syn107_fix.txt', 'rrest-syn024_data.csv', 'rrest-syn103_fix.txt', 'rrest-syn062_data.csv', 'rrest-syn174_fix.txt', 'rrest-syn155_data.csv', 'rrest-syn088_fix.txt', 'rrest-syn056_data.csv', 'rrest-syn129_data.csv', 'rrest-syn173_data.csv', 'rrest-syn173_fix.txt', 'rrest-syn125_fix.txt', 'rrest-syn123_data.csv', 'rrest-syn164_fix.txt', 'rrest-syn176_fix.txt', 'rrest-syn158_fix.txt', 'rrest-syn148_data.csv', 'rrest-syn170_data.csv', 'rrest-syn043_data.csv', 'rrest-syn158_data.csv', 'rrest-syn046_fix.txt', 'rrest-syn113_fix.txt', 'rrest-syn183_data.csv', 'rrest-syn112_fix.txt', 'rrest-syn009_fix.txt', 'rrest-syn151_data.csv', 'rrest-syn081_data.csv', 'rrest-syn038_data.csv', 'rrest-syn068_fix.txt', 'rrest-syn122_fix.txt', 'rrest-syn179_fix.txt', 'rrest-syn067_fix.txt', 'rrest-syn007_fix.txt', 'rrest-syn016_fix.txt', 'rrest-syn174_data.csv', 'rrest-syn032_fix.txt', 'rrest-syn149_fix.txt', 'rrest-syn034_data.csv', 'rrest-syn090_data.csv', 'rrest-syn164_data.csv', 'rrest-syn182_fix.txt', 'rrest-syn180_fix.txt', 'rrest-syn153_fix.txt', 'rrest-syn136_fix.txt', 'rrest-syn018_fix.txt', 'rrest-syn074_fix.txt', 'rrest-syn016_data.csv', 'rrest-syn078_data.csv', 'rrest-syn167_fix.txt', 'rrest-syn062_fix.txt', 'rrest-syn077_fix.txt', 'rrest-syn139_data.csv', 'rrest-syn165_fix.txt', 'rrest-syn044_data.csv', 'rrest-syn033_data.csv', 'rrest-syn134_fix.txt', 'rrest-syn020_fix.txt', 'rrest-syn053_data.csv', 'rrest-syn013_fix.txt', 'rrest-syn131_fix.txt', 'rrest-syn021_data.csv', 'rrest-syn095_fix.txt', 'rrest-syn080_data.csv', 'rrest-syn028_fix.txt', 'rrest-syn177_fix.txt', 'rrest-syn005_data.csv', 'rrest-syn136_data.csv', 'rrest-syn026_fix.txt', 'rrest-syn097_fix.txt', 'rrest-syn104_fix.txt', 'rrest-syn052_data.csv', 'rrest-syn050_fix.txt', 'rrest-syn101_fix.txt', 'rrest-syn155_fix.txt', 'rrest-syn076_fix.txt', 'rrest-syn066_data.csv', 'rrest-syn069_data.csv', 'rrest-syn110_fix.txt', 'rrest-syn041_fix.txt', 'rrest-syn010_fix.txt', 'rrest-syn075_data.csv', 'rrest-syn117_data.csv', 'rrest-syn160_data.csv', 'rrest-syn097_data.csv', 'rrest-syn185_fix.txt', 'rrest-syn182_data.csv', 'rrest-syn004_fix.txt', 'rrest-syn058_fix.txt', 'rrest-syn065_fix.txt', 'rrest-syn111_data.csv', 'rrest-syn072_data.csv', 'rrest-syn142_data.csv']\n",
            "founded 372  filenames in /content/drive/MyDrive/HDA project/Synthetic Data/rrest-syn_csv_arfm_3\n",
            "Founded 186 CSV files...\n",
            "Founded 186 TXT files...\n",
            "['rrest-syn_csv']\n",
            "founded 0  filenames in /content/drive/MyDrive/HDA project/Synthetic Data/rrest-syn_csv_arfm_4\n",
            "founded 372  filenames in /content/drive/MyDrive/HDA project/Synthetic Data/rrest-syn_csv_arfm_4/rrest-syn_csv\n",
            "Founded 186 CSV files...\n",
            "Founded 186 TXT files...\n",
            "['rrest-syn077_data.csv', 'rrest-syn100_data.csv', 'rrest-syn156_data.csv', 'rrest-syn150_data.csv', 'rrest-syn055_data.csv', 'rrest-syn066_fix.txt', 'rrest-syn161_data.csv', 'rrest-syn135_fix.txt', 'rrest-syn109_fix.txt', 'rrest-syn085_data.csv', 'rrest-syn156_fix.txt', 'rrest-syn152_fix.txt', 'rrest-syn160_fix.txt', 'rrest-syn166_data.csv', 'rrest-syn127_data.csv', 'rrest-syn133_data.csv', 'rrest-syn144_data.csv', 'rrest-syn168_data.csv', 'rrest-syn181_fix.txt', 'rrest-syn128_fix.txt', 'rrest-syn014_fix.txt', 'rrest-syn151_fix.txt', 'rrest-syn148_fix.txt', 'rrest-syn061_data.csv', 'rrest-syn082_data.csv', 'rrest-syn032_data.csv', 'rrest-syn102_data.csv', 'rrest-syn039_fix.txt', 'rrest-syn048_fix.txt', 'rrest-syn014_data.csv', 'rrest-syn055_fix.txt', 'rrest-syn070_fix.txt', 'rrest-syn022_fix.txt', 'rrest-syn057_fix.txt', 'rrest-syn090_fix.txt', 'rrest-syn067_data.csv', 'rrest-syn078_fix.txt', 'rrest-syn180_data.csv', 'rrest-syn007_data.csv', 'rrest-syn165_data.csv', 'rrest-syn068_data.csv', 'rrest-syn079_fix.txt', 'rrest-syn053_fix.txt', 'rrest-syn098_data.csv', 'rrest-syn061_fix.txt', 'rrest-syn089_fix.txt', 'rrest-syn017_fix.txt', 'rrest-syn169_fix.txt', 'rrest-syn069_fix.txt', 'rrest-syn035_data.csv', 'rrest-syn109_data.csv', 'rrest-syn065_data.csv', 'rrest-syn107_data.csv', 'rrest-syn001_data.csv', 'rrest-syn021_fix.txt', 'rrest-syn108_fix.txt', 'rrest-syn017_data.csv', 'rrest-syn008_fix.txt', 'rrest-syn126_data.csv', 'rrest-syn181_data.csv', 'rrest-syn093_fix.txt', 'rrest-syn075_fix.txt', 'rrest-syn058_data.csv', 'rrest-syn123_fix.txt', 'rrest-syn087_fix.txt', 'rrest-syn072_fix.txt', 'rrest-syn052_fix.txt', 'rrest-syn002_fix.txt', 'rrest-syn161_fix.txt', 'rrest-syn096_fix.txt', 'rrest-syn099_fix.txt', 'rrest-syn119_data.csv', 'rrest-syn038_fix.txt', 'rrest-syn083_data.csv', 'rrest-syn081_fix.txt', 'rrest-syn172_fix.txt', 'rrest-syn102_fix.txt', 'rrest-syn043_fix.txt', 'rrest-syn091_data.csv', 'rrest-syn171_data.csv', 'rrest-syn050_data.csv', 'rrest-syn130_data.csv', 'rrest-syn024_fix.txt', 'rrest-syn121_data.csv', 'rrest-syn115_data.csv', 'rrest-syn063_fix.txt', 'rrest-syn129_fix.txt', 'rrest-syn025_fix.txt', 'rrest-syn119_fix.txt', 'rrest-syn106_data.csv', 'rrest-syn137_fix.txt', 'rrest-syn145_fix.txt', 'rrest-syn112_data.csv', 'rrest-syn085_fix.txt', 'rrest-syn120_fix.txt', 'rrest-syn003_data.csv', 'rrest-syn175_fix.txt', 'rrest-syn054_fix.txt', 'rrest-syn096_data.csv', 'rrest-syn163_fix.txt', 'rrest-syn027_data.csv', 'rrest-syn004_data.csv', 'rrest-syn030_data.csv', 'rrest-syn023_data.csv', 'rrest-syn110_data.csv', 'rrest-syn019_data.csv', 'rrest-syn022_data.csv', 'rrest-syn020_data.csv', 'rrest-syn049_data.csv', 'rrest-syn039_data.csv', 'rrest-syn029_data.csv', 'rrest-syn184_data.csv', 'rrest-syn051_fix.txt', 'rrest-syn033_fix.txt', 'rrest-syn048_data.csv', 'rrest-syn137_data.csv', 'rrest-syn040_fix.txt', 'rrest-syn086_data.csv', 'rrest-syn140_fix.txt', 'rrest-syn176_data.csv', 'rrest-syn147_data.csv', 'rrest-syn027_fix.txt', 'rrest-syn170_fix.txt', 'rrest-syn036_fix.txt', 'rrest-syn100_fix.txt', 'rrest-syn060_fix.txt', 'rrest-syn094_fix.txt', 'rrest-syn166_fix.txt', 'rrest-syn131_data.csv', 'rrest-syn130_fix.txt', 'rrest-syn091_fix.txt', 'rrest-syn045_data.csv', 'rrest-syn114_fix.txt', 'rrest-syn135_data.csv', 'rrest-syn088_data.csv', 'rrest-syn105_fix.txt', 'rrest-syn028_data.csv', 'rrest-syn057_data.csv', 'rrest-syn045_fix.txt', 'rrest-syn010_data.csv', 'rrest-syn126_fix.txt', 'rrest-syn099_data.csv', 'rrest-syn073_data.csv', 'rrest-syn079_data.csv', 'rrest-syn134_data.csv', 'rrest-syn105_data.csv', 'rrest-syn003_fix.txt', 'rrest-syn143_fix.txt', 'rrest-syn012_fix.txt', 'rrest-syn159_data.csv', 'rrest-syn084_fix.txt', 'rrest-syn051_data.csv', 'rrest-syn064_fix.txt', 'rrest-syn169_data.csv', 'rrest-syn120_data.csv', 'rrest-syn047_data.csv', 'rrest-syn031_fix.txt', 'rrest-syn064_data.csv', 'rrest-syn026_data.csv', 'rrest-syn132_fix.txt', 'rrest-syn076_data.csv', 'rrest-syn142_fix.txt', 'rrest-syn060_data.csv', 'rrest-syn124_fix.txt', 'rrest-syn042_fix.txt', 'rrest-syn184_fix.txt', 'rrest-syn042_data.csv', 'rrest-syn125_data.csv', 'rrest-syn153_data.csv', 'rrest-syn175_data.csv', 'rrest-syn178_fix.txt', 'rrest-syn140_data.csv', 'rrest-syn047_fix.txt', 'rrest-syn117_fix.txt', 'rrest-syn063_data.csv', 'rrest-syn143_data.csv', 'rrest-syn178_data.csv', 'rrest-syn138_fix.txt', 'rrest-syn093_data.csv', 'rrest-syn162_data.csv', 'rrest-syn154_fix.txt', 'rrest-syn011_fix.txt', 'rrest-syn101_data.csv', 'rrest-syn159_fix.txt', 'rrest-syn163_data.csv', 'rrest-syn092_data.csv', 'rrest-syn095_data.csv', 'rrest-syn006_fix.txt', 'rrest-syn040_data.csv', 'rrest-syn082_fix.txt', 'rrest-syn019_fix.txt', 'rrest-syn070_data.csv', 'rrest-syn012_data.csv', 'rrest-syn005_fix.txt', 'rrest-syn138_data.csv', 'rrest-syn098_fix.txt', 'rrest-syn168_fix.txt', 'rrest-syn157_fix.txt', 'rrest-syn171_fix.txt', 'rrest-syn046_data.csv', 'rrest-syn111_fix.txt', 'rrest-syn037_data.csv', 'rrest-syn128_data.csv', 'rrest-syn122_data.csv', 'rrest-syn073_fix.txt', 'rrest-syn034_fix.txt', 'rrest-syn183_fix.txt', 'rrest-syn044_data.csv', 'rrest-syn044_fix.txt', 'rrest-syn144_fix.txt', 'rrest-syn049_fix.txt', 'rrest-syn006_data.csv', 'rrest-syn075_data.csv', 'rrest-syn029_fix.txt', 'rrest-syn033_data.csv', 'rrest-syn141_fix.txt', 'rrest-syn180_fix.txt', 'rrest-syn038_data.csv', 'rrest-syn052_data.csv', 'rrest-syn013_data.csv', 'rrest-syn008_data.csv', 'rrest-syn059_fix.txt', 'rrest-syn139_data.csv', 'rrest-syn026_fix.txt', 'rrest-syn118_fix.txt', 'rrest-syn080_data.csv', 'rrest-syn065_fix.txt', 'rrest-syn179_fix.txt', 'rrest-syn155_data.csv', 'rrest-syn071_data.csv', 'rrest-syn142_data.csv', 'rrest-syn104_data.csv', 'rrest-syn086_fix.txt', 'rrest-syn164_data.csv', 'rrest-syn056_fix.txt', 'rrest-syn157_data.csv', 'rrest-syn004_fix.txt', 'rrest-syn088_fix.txt', 'rrest-syn062_data.csv', 'rrest-syn078_data.csv', 'rrest-syn007_fix.txt', 'rrest-syn177_data.csv', 'rrest-syn131_fix.txt', 'rrest-syn037_fix.txt', 'rrest-syn182_fix.txt', 'rrest-syn018_data.csv', 'rrest-syn132_data.csv', 'rrest-syn016_fix.txt', 'rrest-syn173_fix.txt', 'rrest-syn015_data.csv', 'rrest-syn151_data.csv', 'rrest-syn035_fix.txt', 'rrest-syn018_fix.txt', 'rrest-syn177_fix.txt', 'rrest-syn023_fix.txt', 'rrest-syn087_data.csv', 'rrest-syn097_data.csv', 'rrest-syn160_data.csv', 'rrest-syn162_fix.txt', 'rrest-syn076_fix.txt', 'rrest-syn092_fix.txt', 'rrest-syn028_fix.txt', 'rrest-syn146_fix.txt', 'rrest-syn134_fix.txt', 'rrest-syn123_data.csv', 'rrest-syn016_data.csv', 'rrest-syn058_fix.txt', 'rrest-syn090_data.csv', 'rrest-syn127_fix.txt', 'rrest-syn002_data.csv', 'rrest-syn015_fix.txt', 'rrest-syn036_data.csv', 'rrest-syn031_data.csv', 'rrest-syn106_fix.txt', 'rrest-syn097_fix.txt', 'rrest-syn147_fix.txt', 'rrest-syn172_data.csv', 'rrest-syn174_data.csv', 'rrest-syn121_fix.txt', 'rrest-syn101_fix.txt', 'rrest-syn046_fix.txt', 'rrest-syn071_fix.txt', 'rrest-syn173_data.csv', 'rrest-syn118_data.csv', 'rrest-syn158_fix.txt', 'rrest-syn179_data.csv', 'rrest-syn170_data.csv', 'rrest-syn062_fix.txt', 'rrest-syn010_fix.txt', 'rrest-syn043_data.csv', 'rrest-syn032_fix.txt', 'rrest-syn155_fix.txt', 'rrest-syn152_data.csv', 'rrest-syn117_data.csv', 'rrest-syn110_fix.txt', 'rrest-syn074_data.csv', 'rrest-syn125_fix.txt', 'rrest-syn183_data.csv', 'rrest-syn148_data.csv', 'rrest-syn149_data.csv', 'rrest-syn111_data.csv', 'rrest-syn186_data.csv', 'rrest-syn182_data.csv', 'rrest-syn077_fix.txt', 'rrest-syn034_data.csv', 'rrest-syn080_fix.txt', 'rrest-syn145_data.csv', 'rrest-syn025_data.csv', 'rrest-syn103_data.csv', 'rrest-syn072_data.csv', 'rrest-syn041_data.csv', 'rrest-syn009_data.csv', 'rrest-syn165_fix.txt', 'rrest-syn122_fix.txt', 'rrest-syn139_fix.txt', 'rrest-syn115_fix.txt', 'rrest-syn185_fix.txt', 'rrest-syn050_fix.txt', 'rrest-syn005_data.csv', 'rrest-syn024_data.csv', 'rrest-syn186_fix.txt', 'rrest-syn129_data.csv', 'rrest-syn054_data.csv', 'rrest-syn146_data.csv', 'rrest-syn154_data.csv', 'rrest-syn113_fix.txt', 'rrest-syn164_fix.txt', 'rrest-syn116_data.csv', 'rrest-syn020_fix.txt', 'rrest-syn114_data.csv', 'rrest-syn167_fix.txt', 'rrest-syn041_fix.txt', 'rrest-syn053_data.csv', 'rrest-syn067_fix.txt', 'rrest-syn001_fix.txt', 'rrest-syn108_data.csv', 'rrest-syn136_data.csv', 'rrest-syn124_data.csv', 'rrest-syn174_fix.txt', 'rrest-syn084_data.csv', 'rrest-syn158_data.csv', 'rrest-syn116_fix.txt', 'rrest-syn136_fix.txt', 'rrest-syn021_data.csv', 'rrest-syn103_fix.txt', 'rrest-syn030_fix.txt', 'rrest-syn066_data.csv', 'rrest-syn083_fix.txt', 'rrest-syn185_data.csv', 'rrest-syn089_data.csv', 'rrest-syn141_data.csv', 'rrest-syn068_fix.txt', 'rrest-syn176_fix.txt', 'rrest-syn149_fix.txt', 'rrest-syn081_data.csv', 'rrest-syn074_fix.txt', 'rrest-syn167_data.csv', 'rrest-syn113_data.csv', 'rrest-syn107_fix.txt', 'rrest-syn056_data.csv', 'rrest-syn150_fix.txt', 'rrest-syn095_fix.txt', 'rrest-syn153_fix.txt', 'rrest-syn094_data.csv', 'rrest-syn112_fix.txt', 'rrest-syn011_data.csv', 'rrest-syn069_data.csv', 'rrest-syn133_fix.txt', 'rrest-syn009_fix.txt', 'rrest-syn104_fix.txt', 'rrest-syn013_fix.txt', 'rrest-syn059_data.csv']\n",
            "founded 372  filenames in /content/drive/MyDrive/HDA project/Synthetic Data/rrest-syn_csv_sig_range_3\n",
            "Founded 186 CSV files...\n",
            "Founded 186 TXT files...\n",
            "['rrest-syn036_fix.txt', 'rrest-syn081_fix.txt', 'rrest-syn033_fix.txt', 'rrest-syn099_data.csv', 'rrest-syn131_data.csv', 'rrest-syn067_data.csv', 'rrest-syn181_data.csv', 'rrest-syn024_fix.txt', 'rrest-syn037_data.csv', 'rrest-syn061_fix.txt', 'rrest-syn040_fix.txt', 'rrest-syn166_data.csv', 'rrest-syn008_fix.txt', 'rrest-syn025_fix.txt', 'rrest-syn109_data.csv', 'rrest-syn135_data.csv', 'rrest-syn057_data.csv', 'rrest-syn073_data.csv', 'rrest-syn075_fix.txt', 'rrest-syn084_fix.txt', 'rrest-syn072_fix.txt', 'rrest-syn161_data.csv', 'rrest-syn130_data.csv', 'rrest-syn180_data.csv', 'rrest-syn150_data.csv', 'rrest-syn087_fix.txt', 'rrest-syn108_data.csv', 'rrest-syn070_data.csv', 'rrest-syn163_fix.txt', 'rrest-syn102_data.csv', 'rrest-syn149_data.csv', 'rrest-syn032_data.csv', 'rrest-syn099_fix.txt', 'rrest-syn042_fix.txt', 'rrest-syn153_data.csv', 'rrest-syn126_data.csv', 'rrest-syn060_data.csv', 'rrest-syn137_data.csv', 'rrest-syn172_fix.txt', 'rrest-syn068_data.csv', 'rrest-syn119_fix.txt', 'rrest-syn030_data.csv', 'rrest-syn061_data.csv', 'rrest-syn004_data.csv', 'rrest-syn035_data.csv', 'rrest-syn031_fix.txt', 'rrest-syn007_data.csv', 'rrest-syn142_fix.txt', 'rrest-syn079_fix.txt', 'rrest-syn012_data.csv', 'rrest-syn078_fix.txt', 'rrest-syn175_data.csv', 'rrest-syn151_fix.txt', 'rrest-syn012_fix.txt', 'rrest-syn086_data.csv', 'rrest-syn020_data.csv', 'rrest-syn106_fix.txt', 'rrest-syn123_fix.txt', 'rrest-syn055_data.csv', 'rrest-syn120_data.csv', 'rrest-syn063_fix.txt', 'rrest-syn079_data.csv', 'rrest-syn100_data.csv', 'rrest-syn082_fix.txt', 'rrest-syn169_data.csv', 'rrest-syn147_data.csv', 'rrest-syn058_data.csv', 'rrest-syn157_fix.txt', 'rrest-syn093_fix.txt', 'rrest-syn085_data.csv', 'rrest-syn091_fix.txt', 'rrest-syn134_data.csv', 'rrest-syn023_data.csv', 'rrest-syn101_data.csv', 'rrest-syn096_data.csv', 'rrest-syn050_data.csv', 'rrest-syn110_data.csv', 'rrest-syn175_fix.txt', 'rrest-syn156_data.csv', 'rrest-syn073_fix.txt', 'rrest-syn047_fix.txt', 'rrest-syn017_data.csv', 'rrest-syn106_data.csv', 'rrest-syn130_fix.txt', 'rrest-syn019_data.csv', 'rrest-syn039_data.csv', 'rrest-syn135_fix.txt', 'rrest-syn111_fix.txt', 'rrest-syn064_data.csv', 'rrest-syn045_data.csv', 'rrest-syn128_fix.txt', 'rrest-syn098_data.csv', 'rrest-syn117_fix.txt', 'rrest-syn001_data.csv', 'rrest-syn143_data.csv', 'rrest-syn129_fix.txt', 'rrest-syn132_fix.txt', 'rrest-syn026_data.csv', 'rrest-syn133_data.csv', 'rrest-syn021_fix.txt', 'rrest-syn022_data.csv', 'rrest-syn128_data.csv', 'rrest-syn028_data.csv', 'rrest-syn053_fix.txt', 'rrest-syn171_fix.txt', 'rrest-syn047_data.csv', 'rrest-syn043_fix.txt', 'rrest-syn137_fix.txt', 'rrest-syn069_fix.txt', 'rrest-syn124_fix.txt', 'rrest-syn088_data.csv', 'rrest-syn169_fix.txt', 'rrest-syn054_fix.txt', 'rrest-syn140_data.csv', 'rrest-syn034_fix.txt', 'rrest-syn152_fix.txt', 'rrest-syn100_fix.txt', 'rrest-syn063_data.csv', 'rrest-syn065_data.csv', 'rrest-syn108_fix.txt', 'rrest-syn082_data.csv', 'rrest-syn094_fix.txt', 'rrest-syn090_fix.txt', 'rrest-syn181_fix.txt', 'rrest-syn170_fix.txt', 'rrest-syn114_fix.txt', 'rrest-syn160_fix.txt', 'rrest-syn105_fix.txt', 'rrest-syn184_data.csv', 'rrest-syn076_data.csv', 'rrest-syn168_fix.txt', 'rrest-syn120_fix.txt', 'rrest-syn011_fix.txt', 'rrest-syn070_fix.txt', 'rrest-syn042_data.csv', 'rrest-syn022_fix.txt', 'rrest-syn049_data.csv', 'rrest-syn029_data.csv', 'rrest-syn163_data.csv', 'rrest-syn046_data.csv', 'rrest-syn064_fix.txt', 'rrest-syn055_fix.txt', 'rrest-syn066_fix.txt', 'rrest-syn165_data.csv', 'rrest-syn096_fix.txt', 'rrest-syn133_fix.txt', 'rrest-syn145_fix.txt', 'rrest-syn039_fix.txt', 'rrest-syn115_data.csv', 'rrest-syn105_data.csv', 'rrest-syn014_fix.txt', 'rrest-syn027_fix.txt', 'rrest-syn002_fix.txt', 'rrest-syn127_data.csv', 'rrest-syn126_fix.txt', 'rrest-syn010_data.csv', 'rrest-syn109_fix.txt', 'rrest-syn107_data.csv', 'rrest-syn138_data.csv', 'rrest-syn040_data.csv', 'rrest-syn162_data.csv', 'rrest-syn057_fix.txt', 'rrest-syn019_fix.txt', 'rrest-syn048_fix.txt', 'rrest-syn048_data.csv', 'rrest-syn013_data.csv', 'rrest-syn093_data.csv', 'rrest-syn184_fix.txt', 'rrest-syn006_fix.txt', 'rrest-syn045_fix.txt', 'rrest-syn060_fix.txt', 'rrest-syn161_fix.txt', 'rrest-syn148_fix.txt', 'rrest-syn119_data.csv', 'rrest-syn027_data.csv', 'rrest-syn176_data.csv', 'rrest-syn172_data.csv', 'rrest-syn138_fix.txt', 'rrest-syn098_fix.txt', 'rrest-syn171_data.csv', 'rrest-syn121_data.csv', 'rrest-syn017_fix.txt', 'rrest-syn112_data.csv', 'rrest-syn159_data.csv', 'rrest-syn051_fix.txt', 'rrest-syn168_data.csv', 'rrest-syn056_fix.txt', 'rrest-syn156_fix.txt', 'rrest-syn051_data.csv', 'rrest-syn178_data.csv', 'rrest-syn102_fix.txt', 'rrest-syn077_data.csv', 'rrest-syn092_data.csv', 'rrest-syn054_data.csv', 'rrest-syn005_fix.txt', 'rrest-syn083_data.csv', 'rrest-syn095_data.csv', 'rrest-syn159_fix.txt', 'rrest-syn038_fix.txt', 'rrest-syn154_fix.txt', 'rrest-syn144_data.csv', 'rrest-syn085_fix.txt', 'rrest-syn140_fix.txt', 'rrest-syn089_fix.txt', 'rrest-syn166_fix.txt', 'rrest-syn125_data.csv', 'rrest-syn143_fix.txt', 'rrest-syn052_fix.txt', 'rrest-syn014_data.csv', 'rrest-syn003_data.csv', 'rrest-syn003_fix.txt', 'rrest-syn091_data.csv', 'rrest-syn122_data.csv', 'rrest-syn178_fix.txt', 'rrest-syn139_data.csv', 'rrest-syn089_data.csv', 'rrest-syn129_data.csv', 'rrest-syn176_fix.txt', 'rrest-syn123_data.csv', 'rrest-syn182_fix.txt', 'rrest-syn160_data.csv', 'rrest-syn145_data.csv', 'rrest-syn101_fix.txt', 'rrest-syn041_fix.txt', 'rrest-syn005_data.csv', 'rrest-syn112_fix.txt', 'rrest-syn033_data.csv', 'rrest-syn078_data.csv', 'rrest-syn044_fix.txt', 'rrest-syn004_fix.txt', 'rrest-syn104_fix.txt', 'rrest-syn084_data.csv', 'rrest-syn092_fix.txt', 'rrest-syn074_fix.txt', 'rrest-syn158_fix.txt', 'rrest-syn141_data.csv', 'rrest-syn136_fix.txt', 'rrest-syn147_fix.txt', 'rrest-syn174_fix.txt', 'rrest-syn107_fix.txt', 'rrest-syn186_fix.txt', 'rrest-syn065_fix.txt', 'rrest-syn071_data.csv', 'rrest-syn125_fix.txt', 'rrest-syn186_data.csv', 'rrest-syn008_data.csv', 'rrest-syn081_data.csv', 'rrest-syn179_data.csv', 'rrest-syn077_fix.txt', 'rrest-syn094_data.csv', 'rrest-syn068_fix.txt', 'rrest-syn157_data.csv', 'rrest-syn095_fix.txt', 'rrest-syn009_fix.txt', 'rrest-syn066_data.csv', 'rrest-syn015_data.csv', 'rrest-syn117_data.csv', 'rrest-syn041_data.csv', 'rrest-syn150_fix.txt', 'rrest-syn173_data.csv', 'rrest-syn010_fix.txt', 'rrest-syn146_fix.txt', 'rrest-syn183_fix.txt', 'rrest-syn152_data.csv', 'rrest-syn049_fix.txt', 'rrest-syn021_data.csv', 'rrest-syn018_data.csv', 'rrest-syn182_data.csv', 'rrest-syn183_data.csv', 'rrest-syn127_fix.txt', 'rrest-syn034_data.csv', 'rrest-syn009_data.csv', 'rrest-syn059_data.csv', 'rrest-syn056_data.csv', 'rrest-syn116_data.csv', 'rrest-syn154_data.csv', 'rrest-syn134_fix.txt', 'rrest-syn116_fix.txt', 'rrest-syn155_data.csv', 'rrest-syn167_data.csv', 'rrest-syn080_data.csv', 'rrest-syn016_data.csv', 'rrest-syn174_data.csv', 'rrest-syn097_fix.txt', 'rrest-syn002_data.csv', 'rrest-syn149_fix.txt', 'rrest-syn158_data.csv', 'rrest-syn136_data.csv', 'rrest-syn118_fix.txt', 'rrest-syn103_data.csv', 'rrest-syn122_fix.txt', 'rrest-syn177_data.csv', 'rrest-syn155_fix.txt', 'rrest-syn046_fix.txt', 'rrest-syn038_data.csv', 'rrest-syn075_data.csv', 'rrest-syn007_fix.txt', 'rrest-syn013_fix.txt', 'rrest-syn141_fix.txt', 'rrest-syn087_data.csv', 'rrest-syn118_data.csv', 'rrest-syn076_fix.txt', 'rrest-syn020_fix.txt', 'rrest-syn177_fix.txt', 'rrest-syn032_fix.txt', 'rrest-syn069_data.csv', 'rrest-syn090_data.csv', 'rrest-syn080_fix.txt', 'rrest-syn113_data.csv', 'rrest-syn072_data.csv', 'rrest-syn185_fix.txt', 'rrest-syn179_fix.txt', 'rrest-syn036_data.csv', 'rrest-syn044_data.csv', 'rrest-syn083_fix.txt', 'rrest-syn173_fix.txt', 'rrest-syn018_fix.txt', 'rrest-syn185_data.csv', 'rrest-syn097_data.csv', 'rrest-syn016_fix.txt', 'rrest-syn151_data.csv', 'rrest-syn162_fix.txt', 'rrest-syn132_data.csv', 'rrest-syn111_data.csv', 'rrest-syn026_fix.txt', 'rrest-syn025_data.csv', 'rrest-syn124_data.csv', 'rrest-syn015_fix.txt', 'rrest-syn071_fix.txt', 'rrest-syn146_data.csv', 'rrest-syn086_fix.txt', 'rrest-syn037_fix.txt', 'rrest-syn115_fix.txt', 'rrest-syn029_fix.txt', 'rrest-syn043_data.csv', 'rrest-syn144_fix.txt', 'rrest-syn180_fix.txt', 'rrest-syn035_fix.txt', 'rrest-syn148_data.csv', 'rrest-syn121_fix.txt', 'rrest-syn164_data.csv', 'rrest-syn104_data.csv', 'rrest-syn050_fix.txt', 'rrest-syn103_fix.txt', 'rrest-syn167_fix.txt', 'rrest-syn028_fix.txt', 'rrest-syn153_fix.txt', 'rrest-syn031_data.csv', 'rrest-syn058_fix.txt', 'rrest-syn142_data.csv', 'rrest-syn067_fix.txt', 'rrest-syn062_fix.txt', 'rrest-syn088_fix.txt', 'rrest-syn170_data.csv', 'rrest-syn059_fix.txt', 'rrest-syn053_data.csv', 'rrest-syn139_fix.txt', 'rrest-syn024_data.csv', 'rrest-syn030_fix.txt', 'rrest-syn023_fix.txt', 'rrest-syn006_data.csv', 'rrest-syn011_data.csv', 'rrest-syn164_fix.txt', 'rrest-syn052_data.csv', 'rrest-syn074_data.csv', 'rrest-syn114_data.csv', 'rrest-syn062_data.csv', 'rrest-syn165_fix.txt', 'rrest-syn131_fix.txt', 'rrest-syn113_fix.txt', 'rrest-syn110_fix.txt', 'rrest-syn001_fix.txt']\n",
            "founded 372  filenames in /content/drive/MyDrive/HDA project/Synthetic Data/rrest-syn_csv_sig_range_6\n",
            "Founded 186 CSV files...\n",
            "Founded 186 TXT files...\n",
            "['rrest-syn_csv']\n",
            "founded 0  filenames in /content/drive/MyDrive/HDA project/Synthetic Data/rrest-syn_csv_sig_range_9\n",
            "founded 372  filenames in /content/drive/MyDrive/HDA project/Synthetic Data/rrest-syn_csv_sig_range_9/rrest-syn_csv\n",
            "Founded 186 CSV files...\n",
            "Founded 186 TXT files...\n",
            "['bidmc_28_Numerics.csv', 'bidmc_30_Signals.csv', 'bidmc_06_Fix.txt', 'bidmc_49_Signals.csv', 'bidmc_29_Fix.txt', 'bidmc_47_Numerics.csv', 'bidmc_42_Signals.csv', 'bidmc_30_Breaths.csv', 'bidmc_36_Breaths.csv', 'bidmc_20_Numerics.csv', 'bidmc_52_Numerics.csv', 'bidmc_23_Numerics.csv', 'bidmc_44_Breaths.csv', 'bidmc_41_Numerics.csv', 'bidmc_15_Numerics.csv', 'bidmc_47_Fix.txt', 'bidmc_19_Fix.txt', 'bidmc_53_Fix.txt', 'bidmc_14_Breaths.csv', 'bidmc_05_Fix.txt', 'bidmc_48_Numerics.csv', 'bidmc_34_Breaths.csv', 'bidmc_12_Signals.csv', 'bidmc_31_Breaths.csv', 'bidmc_33_Numerics.csv', 'bidmc_41_Fix.txt', 'bidmc_52_Fix.txt', 'bidmc_10_Fix.txt', 'bidmc_04_Fix.txt', 'bidmc_48_Fix.txt', 'bidmc_42_Breaths.csv', 'bidmc_06_Breaths.csv', 'bidmc_22_Signals.csv', 'bidmc_41_Breaths.csv', 'bidmc_32_Numerics.csv', 'bidmc_02_Breaths.csv', 'bidmc_09_Numerics.csv', 'bidmc_50_Fix.txt', 'bidmc_01_Fix.txt', 'bidmc_22_Breaths.csv', 'bidmc_35_Numerics.csv', 'bidmc_43_Numerics.csv', 'bidmc_31_Fix.txt', 'bidmc_15_Fix.txt', 'bidmc_37_Numerics.csv', 'bidmc_20_Breaths.csv', 'bidmc_33_Breaths.csv', 'bidmc_51_Signals.csv', 'bidmc_51_Fix.txt', 'bidmc_31_Numerics.csv', 'bidmc_05_Breaths.csv', 'bidmc_38_Signals.csv', 'bidmc_01_Signals.csv', 'bidmc_07_Signals.csv', 'bidmc_52_Breaths.csv', 'bidmc_40_Fix.txt', 'bidmc_22_Numerics.csv', 'bidmc_49_Fix.txt', 'bidmc_11_Numerics.csv', 'bidmc_34_Signals.csv', 'bidmc_15_Breaths.csv', 'bidmc_48_Signals.csv', 'bidmc_07_Numerics.csv', 'bidmc_34_Numerics.csv', 'bidmc_26_Breaths.csv', 'bidmc_26_Fix.txt', 'bidmc_21_Fix.txt', 'bidmc_03_Breaths.csv', 'bidmc_12_Numerics.csv', 'bidmc_17_Signals.csv', 'bidmc_29_Signals.csv', 'bidmc_14_Numerics.csv', 'bidmc_25_Numerics.csv', 'bidmc_37_Fix.txt', 'bidmc_46_Breaths.csv', 'bidmc_27_Signals.csv', 'bidmc_45_Fix.txt', 'bidmc_39_Numerics.csv', 'bidmc_08_Numerics.csv', 'bidmc_16_Signals.csv', 'bidmc_28_Fix.txt', 'bidmc_50_Numerics.csv', 'bidmc_48_Breaths.csv', 'bidmc_53_Signals.csv', 'bidmc_01_Breaths.csv', 'bidmc_13_Breaths.csv', 'bidmc_04_Numerics.csv', 'bidmc_18_Fix.txt', 'bidmc_21_Numerics.csv', 'bidmc_35_Signals.csv', 'bidmc_45_Numerics.csv', 'bidmc_11_Fix.txt', 'bidmc_11_Signals.csv', 'bidmc_40_Signals.csv', 'bidmc_22_Fix.txt', 'bidmc_42_Fix.txt', 'bidmc_39_Breaths.csv', 'bidmc_37_Breaths.csv', 'bidmc_38_Numerics.csv', 'bidmc_39_Signals.csv', 'bidmc_36_Fix.txt', 'bidmc_28_Breaths.csv', 'bidmc_04_Breaths.csv', 'bidmc_45_Breaths.csv', 'bidmc_03_Signals.csv', 'bidmc_09_Fix.txt', 'bidmc_02_Fix.txt', 'bidmc_10_Signals.csv', 'bidmc_08_Signals.csv', 'bidmc_13_Signals.csv', 'bidmc_30_Numerics.csv', 'bidmc_07_Breaths.csv', 'bidmc_32_Breaths.csv', 'bidmc_23_Fix.txt', 'bidmc_23_Breaths.csv', 'bidmc_39_Fix.txt', 'bidmc_49_Numerics.csv', 'bidmc_14_Signals.csv', 'bidmc_18_Breaths.csv', 'bidmc_36_Signals.csv', 'bidmc_21_Signals.csv', 'bidmc_13_Numerics.csv', 'bidmc_46_Fix.txt', 'bidmc_10_Numerics.csv', 'bidmc_07_Fix.txt', 'bidmc_13_Fix.txt', 'bidmc_27_Breaths.csv', 'bidmc_17_Fix.txt', 'bidmc_05_Signals.csv', 'bidmc_49_Breaths.csv', 'bidmc_29_Numerics.csv', 'bidmc_47_Signals.csv', 'bidmc_32_Signals.csv', 'bidmc_18_Signals.csv', 'bidmc_06_Signals.csv', 'bidmc_15_Signals.csv', 'bidmc_16_Fix.txt', 'bidmc_46_Signals.csv', 'bidmc_14_Fix.txt', 'bidmc_25_Fix.txt', 'bidmc_01_Numerics.csv', 'bidmc_18_Numerics.csv', 'bidmc_10_Breaths.csv', 'bidmc_25_Signals.csv', 'bidmc_50_Breaths.csv', 'bidmc_08_Breaths.csv', 'bidmc_44_Fix.txt', 'bidmc_43_Fix.txt', 'bidmc_26_Signals.csv', 'bidmc_20_Signals.csv', 'bidmc_45_Signals.csv', 'bidmc_29_Breaths.csv', 'bidmc_33_Fix.txt', 'bidmc_43_Breaths.csv', 'bidmc_09_Signals.csv', 'bidmc_35_Fix.txt', 'bidmc_50_Signals.csv', 'bidmc_05_Numerics.csv', 'bidmc_23_Signals.csv', 'bidmc_51_Numerics.csv', 'bidmc_44_Numerics.csv', 'bidmc_06_Numerics.csv', 'bidmc_25_Breaths.csv', 'bidmc_33_Signals.csv', 'bidmc_16_Numerics.csv', 'bidmc_12_Breaths.csv', 'bidmc_20_Fix.txt', 'bidmc_24_Numerics.csv', 'bidmc_37_Signals.csv', 'bidmc_32_Fix.txt', 'bidmc_19_Signals.csv', 'bidmc_30_Fix.txt', 'bidmc_04_Signals.csv', 'bidmc_38_Breaths.csv', 'bidmc_51_Breaths.csv', 'bidmc_27_Fix.txt', 'bidmc_21_Breaths.csv', 'bidmc_43_Signals.csv', 'bidmc_24_Signals.csv', 'bidmc_53_Numerics.csv', 'bidmc_40_Numerics.csv', 'bidmc_24_Breaths.csv', 'bidmc_35_Breaths.csv', 'bidmc_34_Fix.txt', 'bidmc_36_Numerics.csv', 'bidmc_27_Numerics.csv', 'bidmc_52_Signals.csv', 'bidmc_08_Fix.txt', 'bidmc_31_Signals.csv', 'bidmc_28_Signals.csv', 'bidmc_42_Numerics.csv', 'bidmc_17_Breaths.csv', 'bidmc_24_Fix.txt', 'bidmc_47_Breaths.csv', 'bidmc_11_Breaths.csv', 'bidmc_02_Numerics.csv', 'bidmc_09_Breaths.csv', 'bidmc_53_Breaths.csv', 'bidmc_26_Numerics.csv', 'bidmc_03_Fix.txt', 'bidmc_40_Breaths.csv', 'bidmc_12_Fix.txt', 'bidmc_02_Signals.csv', 'bidmc_46_Numerics.csv', 'bidmc_03_Numerics.csv', 'bidmc_17_Numerics.csv', 'bidmc_44_Signals.csv', 'bidmc_16_Breaths.csv', 'bidmc_19_Breaths.csv', 'bidmc_38_Fix.txt', 'bidmc_19_Numerics.csv', 'bidmc_41_Signals.csv']\n",
            "founded 212  filenames in /content/drive/MyDrive/HDA project/Synthetic Data/BIMDC\n",
            "Founded 159 CSV files...\n",
            "Founded 53 TXT files...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Data are chosen until 171 because the other parts are related to the ECG.\n",
        "\n",
        "csvs_syn_ar02=csvs_syn_ar02[:171]\n",
        "csvs_syn_ar03=csvs_syn_ar03[:171]\n",
        "csvs_syn_ar04=csvs_syn_ar04[:171]\n",
        "\n",
        "csvs_syn_arfm3=csvs_syn_arfm3[:171]\n",
        "csvs_syn_arfm4=csvs_syn_arfm4[:171]\n",
        "\n",
        "csvs_syn_range3=csvs_syn_range3[:171]\n",
        "csvs_syn_range6=csvs_syn_range6[:171]\n",
        "csvs_syn_range9=csvs_syn_range9[:171]\n",
        "\n",
        "csvs_syn=csvs_syn[:171]\n",
        "\n"
      ],
      "metadata": {
        "id": "INjMsSZod29-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pulse oximiter Data"
      ],
      "metadata": {
        "id": "Ha8rCKKLenTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path_recorded= \"/content/drive/MyDrive/HDA project/Csv Recordings\"\n",
        "\n",
        "csvs_recorded, txts_recorded= list_csv_txt(folder_path_recorded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbuJnnc2bsSj",
        "outputId": "96f457a2-1544-4dda-e7f5-a885c19b0f5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['REMOCOP_19_2022127_17h55.csv', 'REMOCOP_17_2022127_18h13.csv', 'REMOCOP_20_2022127_18h15.csv', 'REMOCOP_18_2022127_18h18.csv', 'REMOCOP_18_2022127_18h21.csv', 'REMOCOP_VIDEO_2022127_21h50.csv', 'REMOCOP_VIDEO_2022127_21h59.csv', 'REMOCOP_VIDEO_2022127_22h11.csv', '.ipynb_checkpoints', '20211211_20_15h43.csv', '20211211_25_15h48.csv', 'REMOCOP_VIDEO_2022128_12h8.csv', 'REMOCOP_VIDEO_2022128_13h42.csv', 'description.txt']\n",
            "founded 13  filenames in /content/drive/MyDrive/HDA project/Csv Recordings\n",
            "founded 0  filenames in /content/drive/MyDrive/HDA project/Csv Recordings/.ipynb_checkpoints\n",
            "Founded 12 CSV files...\n",
            "Founded 1 TXT files...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "dfs = data_load_for_recordings(csvs_recorded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuNdoS7jbxyU",
        "outputId": "ce9de2de-1008-470f-e87b-efc1a1fa1b07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/HDA project/Csv Recordings/20211211_20_15h43.csv\n",
            "/content/drive/MyDrive/HDA project/Csv Recordings/20211211_25_15h48.csv\n",
            "/content/drive/MyDrive/HDA project/Csv Recordings/REMOCOP_17_2022127_18h13.csv\n",
            "/content/drive/MyDrive/HDA project/Csv Recordings/REMOCOP_18_2022127_18h18.csv\n",
            "/content/drive/MyDrive/HDA project/Csv Recordings/REMOCOP_18_2022127_18h21.csv\n",
            "/content/drive/MyDrive/HDA project/Csv Recordings/REMOCOP_19_2022127_17h55.csv\n",
            "/content/drive/MyDrive/HDA project/Csv Recordings/REMOCOP_20_2022127_18h15.csv\n",
            "/content/drive/MyDrive/HDA project/Csv Recordings/REMOCOP_VIDEO_2022127_21h50.csv\n",
            "/content/drive/MyDrive/HDA project/Csv Recordings/REMOCOP_VIDEO_2022127_21h59.csv\n",
            "/content/drive/MyDrive/HDA project/Csv Recordings/REMOCOP_VIDEO_2022127_22h11.csv\n",
            "/content/drive/MyDrive/HDA project/Csv Recordings/REMOCOP_VIDEO_2022128_12h8.csv\n",
            "/content/drive/MyDrive/HDA project/Csv Recordings/REMOCOP_VIDEO_2022128_13h42.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = get_label_recorded('/content/drive/MyDrive/HDA project/Labels')\n",
        "recorded, label_recorded = get_recorded(dfs, get_frequency(txts_recorded), label_dict)"
      ],
      "metadata": {
        "id": "a7kO7zXz4-m1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9c6461f-a98d-40a2-eaaf-dcf009fb6ea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------\n",
            "dfs 0 too small! go further!\n",
            "------------------------------------------------------------\n",
            "missing --->  955 rows\n",
            "Splitting dfs 1 in 1\n",
            "labels 1\n",
            "recorded array (1, 5801)\n",
            "merged (1, 5801)\n",
            "------------------------------------------------------------\n",
            "dfs 2 too small! go further!\n",
            "------------------------------------------------------------\n",
            "missing --->  395 rows\n",
            "Splitting dfs 3 in 1\n",
            "labels 2\n",
            "recorded array (1, 5801)\n",
            "merged (2, 5801)\n",
            "------------------------------------------------------------\n",
            "missing --->  119 rows\n",
            "Splitting dfs 4 in 1\n",
            "labels 3\n",
            "recorded array (1, 5801)\n",
            "merged (3, 5801)\n",
            "------------------------------------------------------------\n",
            "missing --->  1142 rows\n",
            "Splitting dfs 5 in 1\n",
            "labels 4\n",
            "recorded array (1, 5801)\n",
            "merged (4, 5801)\n",
            "------------------------------------------------------------\n",
            "missing --->  666 rows\n",
            "Splitting dfs 6 in 1\n",
            "labels 5\n",
            "recorded array (1, 5801)\n",
            "merged (5, 5801)\n",
            "------------------------------------------------------------\n",
            "missing --->  256 rows\n",
            "Splitting dfs 7 in 3\n",
            "labels 8\n",
            "recorded array (3, 5801)\n",
            "merged (8, 5801)\n",
            "------------------------------------------------------------\n",
            "missing --->  422 rows\n",
            "Splitting dfs 8 in 6\n",
            "labels 14\n",
            "recorded array (6, 5801)\n",
            "merged (14, 5801)\n",
            "------------------------------------------------------------\n",
            "missing --->  605 rows\n",
            "Splitting dfs 9 in 10\n",
            "labels 24\n",
            "recorded array (10, 5801)\n",
            "merged (24, 5801)\n",
            "------------------------------------------------------------\n",
            "missing --->  1732 rows\n",
            "Splitting dfs 10 in 40\n",
            "labels 64\n",
            "recorded array (40, 5801)\n",
            "merged (64, 5801)\n",
            "------------------------------------------------------------\n",
            "missing --->  843 rows\n",
            "Splitting dfs 11 in 20\n",
            "labels 64\n",
            "merged (64, 5801)\n",
            "Final Merged: (64, 5801)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler= StandardScaler()\n",
        "scaler.fit(recorded)\n",
        "recorded_scaled = scaler.transform(recorded)"
      ],
      "metadata": {
        "id": "_Gta6DZwWCxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(label_recorded))\n",
        "indices = [i for i, x in enumerate(label_recorded) if x != 0]\n",
        "label_recorded = [label_recorded[index] for index in indices]\n",
        "print(len(label_recorded))\n",
        "\n",
        "recorded_scaled=recorded_scaled[indices]\n",
        "recorded_scaled=recorded_scaled[..., np.newaxis]\n",
        "print(recorded_scaled.shape)"
      ],
      "metadata": {
        "id": "EqA9GT1-dbaW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7fcd106-21f8-4a80-e5a3-8fd709c976e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64\n",
            "53\n",
            "(53, 5801, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BIDMC"
      ],
      "metadata": {
        "id": "XrDhnMDtfKpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_array_bimdc, list_label_bimdc= read_bimdc(csvs_real)\n",
        "print(len(list_array_bimdc))\n",
        "print(len(list_label_bimdc))\n",
        "print(list_array_bimdc[0].shape)\n",
        "print(list_label_bimdc  [0].shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqMzAZfnV5Si",
        "outputId": "1d2363fc-8be4-4326-af52-19bb68ebe417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53\n",
            "53\n",
            "(60001,)\n",
            "(481, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_real = get_bimdc(list_array_bimdc)\n",
        "y_real, indices = get_bimdc_label(list_label_bimdc)\n",
        "X_real = X_real[indices]\n",
        "\n",
        "print(X_real.shape)\n",
        "print(len(y_real))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4YUX74UVz2r",
        "outputId": "9572818b-c3f1-4fba-86cc-83f477985033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(418, 5801)\n",
            "418\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "Uryh4J6Efej8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_module(layer_in, n_filters, kernel=3):\n",
        "  merge_input = layer_in\n",
        "  # check if the number of filters needs to be increase, assumes channels last format\n",
        "  # if layer_in.shape[-1] != n_filters:\n",
        "  merge_input = tf.keras.layers.Conv1D(n_filters, kernel_size=1, padding='same', strides=2)(layer_in)\n",
        "  conv1 = tf.keras.layers.Conv1D(n_filters, kernel_size=kernel,padding='same', strides=2)(layer_in)\n",
        "  conv2 = tf.keras.layers.Conv1D(n_filters, kernel_size=kernel,padding='same', strides=1)(conv1)\n",
        "  conv3 = tf.keras.layers.Conv1D(n_filters, kernel_size=kernel, padding='same',strides=1)(conv2)\n",
        "  conv4 = tf.keras.layers.Conv1D(n_filters, kernel_size=kernel, padding='same',strides=1)(conv3)\n",
        "\n",
        "\n",
        "  # add filters, assumes filters/channels last\n",
        "  layer_out = tf.keras.layers.add([conv4, merge_input])\n",
        "  # activation function\n",
        "  layer_out = tf.keras.layers.Activation('relu')(layer_out)\n",
        "  return layer_out\n",
        "# define model input\n",
        "# prova=X_train.reshape(1,30000, 20160)\n",
        "def create_model():\n",
        "  visible =  tf.keras.layers.Input(shape=(X_train.shape[1],1) )\n",
        "\n",
        "  res_block = residual_module(visible,n_filters=6 ) \n",
        "  res_block = residual_module(res_block, n_filters=12)\n",
        "  res_block = residual_module(res_block, n_filters=12)\n",
        "  res_block = residual_module(res_block, n_filters=12)\n",
        "  res_block = residual_module(res_block, n_filters=12)\n",
        "\n",
        "\n",
        "  x = tf.keras.layers.AveragePooling1D(strides=2, padding='same') (res_block)\n",
        "\n",
        "  x = tf.keras.layers.Flatten() (x)\n",
        "  x = tf.keras.layers.Dense(20) (x)\n",
        "  x = tf.keras.layers.Dense(10) (x)\n",
        "  x = tf.keras.layers.Dense(1, activation=\"relu\") (x)\n",
        "\n",
        "\n",
        "  # create model\n",
        "  model = tf.keras.Model(inputs=visible, outputs=x)\n",
        "  model.compile(optimizer='Adam', loss='mean_absolute_error')\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "NW9baq4JfkmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments"
      ],
      "metadata": {
        "id": "nnplmE7qfm5J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Standard: AM =0.1 BW = 0.05, General Amplitude = 1"
      ],
      "metadata": {
        "id": "JRPEipGjFpum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_synthetic_array_syn=read_csv_file(csvs_syn)\n",
        "X_syn, dim=get_synthetic_data(csvs_syn, txts_syn, df_synthetic_array_syn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCHpHhHYFpum",
        "outputId": "6f6c83f3-5b76-44cf-e1d5-f305fea9a14d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what merged so far:  (3040, 5801)\n",
            "what merged so far:  (6080, 5801)\n",
            "what merged so far:  (9120, 5801)\n",
            "what merged so far:  (12160, 5801)\n",
            "final merge shape (13224, 5801)\n",
            "----------------------------------------\n",
            "Time Execution: \n",
            "--- 7.13 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_scaled_syn = scaler.transform(X_syn) \n",
        "X_scaled_real = scaler.transform(X_real) \n",
        "print(X_scaled_syn.shape)\n",
        "print(X_scaled_real.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkF2P-MSFpum",
        "outputId": "bce7025d-23ef-4b91-b5c7-0410dd4b21bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13224, 5801)\n",
            "(418, 5801)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.concatenate((X_scaled_syn, X_scaled_real), axis=0)\n",
        "X = X[..., np.newaxis] \n",
        "\n",
        "print(X.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gg5C6d52Fpum",
        "outputId": "f8c5aea0-7d2c-423b-a54c-2eddb3a05e72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13642, 5801, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_synthetic = ([i for i in range(4,61,2)]*3)*1\n",
        "y_syn = [label_synthetic[i//dim] for i in range(len(label_synthetic)*dim)]\n",
        "\n",
        "y=y_syn+y_real\n",
        "print(len(y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcfbux_EFpum",
        "outputId": "2d2bde2d-3ca2-4015-9b36-6fcba5b9a6e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test=train_test_split(X,y, test_size=0.3, \n",
        "                                                  shuffle=True, random_state=1)\n",
        "# X_train, X_val, y_train, y_val=train_test_split(X_train,y_train, test_size=0.2, \n",
        "#                                                   shuffle=True, random_state=1)\n"
      ],
      "metadata": {
        "id": "58VMddYCFpun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "\n",
        "print(\"X_train:\",X_train.shape, \"y_train:\",len(y_train))\n",
        "print(\"X_test:\",X_test.shape, \"y_test:\",len(y_test))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQqzoSFlFpun",
        "outputId": "4e5021b3-af54-41cb-f67e-f0aecf778f92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (9549, 5801, 1) y_train: 9549\n",
            "X_test: (4093, 5801, 1) y_test: 4093\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Merge inputs and targets\n",
        "inputs = np.concatenate((X_train, X_test), axis=0)\n",
        "targets = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=5, shuffle=True)\n",
        "loss_per_fold=[]\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "es = EarlyStopping(monitor='val_loss', mode='min',verbose=1, patience=5)\n",
        "\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "\n",
        "  # Define the model architecture\n",
        "  model = create_model()\n",
        "\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit(inputs[train], targets[train], validation_data=(inputs[test], targets[test]), batch_size=254, epochs =100, \n",
        "                      callbacks=[es])\n",
        "  # Generate generalization metrics\n",
        "  scores = model.evaluate(recorded_scaled, np.array(label_recorded), verbose=0)\n",
        "  # print(f'Score for fold {fold_no}: {model.metrics_names} of {scores}')\n",
        "  print(f'MY DATA: Score for fold {fold_no}: {model.metrics_names} of {scores}')\n",
        "  loss_per_fold.append(scores)\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75b966e2-9276-4035-de65-80f1f59ede76",
        "id": "exWxqnW_Fpun"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/100\n",
            "43/43 [==============================] - 4s 52ms/step - loss: 16.6058 - val_loss: 11.7760\n",
            "Epoch 2/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 9.3089 - val_loss: 7.2613\n",
            "Epoch 3/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 5.3826 - val_loss: 3.9093\n",
            "Epoch 4/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 3.8427 - val_loss: 3.1294\n",
            "Epoch 5/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 2.6318 - val_loss: 2.8181\n",
            "Epoch 6/100\n",
            "43/43 [==============================] - 2s 38ms/step - loss: 2.4941 - val_loss: 2.4695\n",
            "Epoch 7/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 2.3511 - val_loss: 2.0268\n",
            "Epoch 8/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 2.0422 - val_loss: 1.9586\n",
            "Epoch 9/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.9433 - val_loss: 1.9377\n",
            "Epoch 10/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 2.0558 - val_loss: 2.0912\n",
            "Epoch 11/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.7768 - val_loss: 1.8862\n",
            "Epoch 12/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.6695 - val_loss: 1.6700\n",
            "Epoch 13/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.6724 - val_loss: 1.4116\n",
            "Epoch 14/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.4778 - val_loss: 1.4937\n",
            "Epoch 15/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.5502 - val_loss: 1.2579\n",
            "Epoch 16/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.3828 - val_loss: 1.5029\n",
            "Epoch 17/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.3523 - val_loss: 1.1819\n",
            "Epoch 18/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.3969 - val_loss: 2.3608\n",
            "Epoch 19/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.7441 - val_loss: 1.1947\n",
            "Epoch 20/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.2126 - val_loss: 1.6966\n",
            "Epoch 21/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.1325 - val_loss: 0.9436\n",
            "Epoch 22/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.2812 - val_loss: 2.3820\n",
            "Epoch 23/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.5237 - val_loss: 1.1439\n",
            "Epoch 24/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.2260 - val_loss: 1.3132\n",
            "Epoch 25/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.0307 - val_loss: 0.9709\n",
            "Epoch 26/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.0644 - val_loss: 0.9529\n",
            "Epoch 26: early stopping\n",
            "MY DATA: Score for fold 1: ['loss'] of 2.7290632724761963\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/100\n",
            "43/43 [==============================] - 4s 46ms/step - loss: 17.5059 - val_loss: 12.8636\n",
            "Epoch 2/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 9.8169 - val_loss: 7.3120\n",
            "Epoch 3/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 6.3916 - val_loss: 4.9904\n",
            "Epoch 4/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 4.9944 - val_loss: 5.4857\n",
            "Epoch 5/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 3.8026 - val_loss: 2.9682\n",
            "Epoch 6/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 2.8904 - val_loss: 2.9572\n",
            "Epoch 7/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 2.7363 - val_loss: 2.4079\n",
            "Epoch 8/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 2.2944 - val_loss: 2.0754\n",
            "Epoch 9/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 2.1311 - val_loss: 1.9356\n",
            "Epoch 10/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.8747 - val_loss: 1.7521\n",
            "Epoch 11/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.8467 - val_loss: 1.7183\n",
            "Epoch 12/100\n",
            "43/43 [==============================] - 2s 38ms/step - loss: 1.6438 - val_loss: 1.9506\n",
            "Epoch 13/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 2.0516 - val_loss: 1.5619\n",
            "Epoch 14/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.5735 - val_loss: 1.4919\n",
            "Epoch 15/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.5146 - val_loss: 1.3988\n",
            "Epoch 16/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.4269 - val_loss: 1.2930\n",
            "Epoch 17/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.3158 - val_loss: 1.2371\n",
            "Epoch 18/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.3246 - val_loss: 1.2700\n",
            "Epoch 19/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.4484 - val_loss: 1.5782\n",
            "Epoch 20/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.2600 - val_loss: 1.2064\n",
            "Epoch 21/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.2820 - val_loss: 1.3176\n",
            "Epoch 22/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.3219 - val_loss: 1.2782\n",
            "Epoch 23/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.2437 - val_loss: 1.1420\n",
            "Epoch 24/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.2223 - val_loss: 1.2739\n",
            "Epoch 25/100\n",
            "43/43 [==============================] - 2s 38ms/step - loss: 1.2760 - val_loss: 1.1944\n",
            "Epoch 26/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.5765 - val_loss: 1.4037\n",
            "Epoch 27/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.2108 - val_loss: 1.1107\n",
            "Epoch 28/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.0392 - val_loss: 1.0413\n",
            "Epoch 29/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.1541 - val_loss: 1.2144\n",
            "Epoch 30/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.1319 - val_loss: 1.1173\n",
            "Epoch 31/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.0018 - val_loss: 1.0531\n",
            "Epoch 32/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.0587 - val_loss: 1.0914\n",
            "Epoch 33/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.4046 - val_loss: 1.6554\n",
            "Epoch 33: early stopping\n",
            "MY DATA: Score for fold 2: ['loss'] of 4.857781887054443\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/100\n",
            "43/43 [==============================] - 4s 52ms/step - loss: 15.7316 - val_loss: 9.7671\n",
            "Epoch 2/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 7.3296 - val_loss: 5.4443\n",
            "Epoch 3/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 4.3599 - val_loss: 4.3504\n",
            "Epoch 4/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 3.2095 - val_loss: 2.6106\n",
            "Epoch 5/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 3.2550 - val_loss: 3.2333\n",
            "Epoch 6/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 2.4505 - val_loss: 2.2264\n",
            "Epoch 7/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 2.6221 - val_loss: 2.7051\n",
            "Epoch 8/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 2.3606 - val_loss: 2.4678\n",
            "Epoch 9/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 2.1567 - val_loss: 2.0285\n",
            "Epoch 10/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 2.7422 - val_loss: 2.6109\n",
            "Epoch 11/100\n",
            "43/43 [==============================] - 2s 40ms/step - loss: 1.9009 - val_loss: 1.7074\n",
            "Epoch 12/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.7048 - val_loss: 1.6761\n",
            "Epoch 13/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.6025 - val_loss: 1.6906\n",
            "Epoch 14/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.7458 - val_loss: 2.2399\n",
            "Epoch 15/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.7760 - val_loss: 1.5970\n",
            "Epoch 16/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.4652 - val_loss: 1.3697\n",
            "Epoch 17/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.8639 - val_loss: 1.7986\n",
            "Epoch 18/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.7998 - val_loss: 1.9168\n",
            "Epoch 19/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.6774 - val_loss: 1.8069\n",
            "Epoch 20/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.3885 - val_loss: 1.2807\n",
            "Epoch 21/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.4076 - val_loss: 1.2998\n",
            "Epoch 22/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.3285 - val_loss: 1.2732\n",
            "Epoch 23/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.4302 - val_loss: 1.5146\n",
            "Epoch 24/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.5564 - val_loss: 1.5727\n",
            "Epoch 25/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.2861 - val_loss: 2.0185\n",
            "Epoch 26/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.6240 - val_loss: 1.4175\n",
            "Epoch 27/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.3687 - val_loss: 1.6865\n",
            "Epoch 27: early stopping\n",
            "MY DATA: Score for fold 3: ['loss'] of 6.990306854248047\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/100\n",
            "43/43 [==============================] - 4s 46ms/step - loss: 16.8222 - val_loss: 12.4707\n",
            "Epoch 2/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 9.9531 - val_loss: 7.3391\n",
            "Epoch 3/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 6.7204 - val_loss: 5.5150\n",
            "Epoch 4/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 3.9365 - val_loss: 2.6852\n",
            "Epoch 5/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 2.6394 - val_loss: 2.3036\n",
            "Epoch 6/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 2.1845 - val_loss: 2.6088\n",
            "Epoch 7/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 2.2453 - val_loss: 2.1104\n",
            "Epoch 8/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.7462 - val_loss: 1.6694\n",
            "Epoch 9/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.7606 - val_loss: 1.6378\n",
            "Epoch 10/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.6917 - val_loss: 1.5637\n",
            "Epoch 11/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.6753 - val_loss: 2.0205\n",
            "Epoch 12/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.5029 - val_loss: 1.3214\n",
            "Epoch 13/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.2639 - val_loss: 1.3312\n",
            "Epoch 14/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.0644 - val_loss: 0.9977\n",
            "Epoch 15/100\n",
            "43/43 [==============================] - 2s 39ms/step - loss: 1.1300 - val_loss: 1.3664\n",
            "Epoch 16/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.2434 - val_loss: 1.5204\n",
            "Epoch 17/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.4047 - val_loss: 3.2484\n",
            "Epoch 18/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.1541 - val_loss: 1.2670\n",
            "Epoch 19/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.4714 - val_loss: 1.1344\n",
            "Epoch 19: early stopping\n",
            "MY DATA: Score for fold 4: ['loss'] of 5.760232448577881\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/100\n",
            "43/43 [==============================] - 4s 46ms/step - loss: 16.6892 - val_loss: 12.9774\n",
            "Epoch 2/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 9.9686 - val_loss: 6.7602\n",
            "Epoch 3/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 7.0117 - val_loss: 5.7541\n",
            "Epoch 4/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 5.6271 - val_loss: 5.8318\n",
            "Epoch 5/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 4.1976 - val_loss: 4.0681\n",
            "Epoch 6/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 2.9313 - val_loss: 2.3593\n",
            "Epoch 7/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 2.3116 - val_loss: 1.9608\n",
            "Epoch 8/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 2.1294 - val_loss: 2.1374\n",
            "Epoch 9/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 2.3424 - val_loss: 1.8728\n",
            "Epoch 10/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.8658 - val_loss: 1.5521\n",
            "Epoch 11/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.6994 - val_loss: 1.6276\n",
            "Epoch 12/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.5425 - val_loss: 1.8204\n",
            "Epoch 13/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.8817 - val_loss: 1.7867\n",
            "Epoch 14/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.6709 - val_loss: 1.7914\n",
            "Epoch 15/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.3914 - val_loss: 1.2718\n",
            "Epoch 16/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.7992 - val_loss: 1.5439\n",
            "Epoch 17/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.6937 - val_loss: 1.2090\n",
            "Epoch 18/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.2857 - val_loss: 1.1643\n",
            "Epoch 19/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.4004 - val_loss: 1.3896\n",
            "Epoch 20/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.1662 - val_loss: 1.1567\n",
            "Epoch 21/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.4225 - val_loss: 1.4658\n",
            "Epoch 22/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.3345 - val_loss: 1.1984\n",
            "Epoch 23/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.2045 - val_loss: 1.1723\n",
            "Epoch 24/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.1912 - val_loss: 1.1290\n",
            "Epoch 25/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.1568 - val_loss: 1.0170\n",
            "Epoch 26/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.3745 - val_loss: 1.1095\n",
            "Epoch 27/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.2383 - val_loss: 1.4635\n",
            "Epoch 28/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.0112 - val_loss: 1.0696\n",
            "Epoch 29/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.0675 - val_loss: 1.0216\n",
            "Epoch 30/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 0.9561 - val_loss: 0.8748\n",
            "Epoch 31/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.2516 - val_loss: 1.5769\n",
            "Epoch 32/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.0277 - val_loss: 0.8656\n",
            "Epoch 33/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 0.9707 - val_loss: 0.8964\n",
            "Epoch 34/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.0064 - val_loss: 0.8946\n",
            "Epoch 35/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.0285 - val_loss: 1.5893\n",
            "Epoch 36/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.0912 - val_loss: 0.8472\n",
            "Epoch 37/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.0256 - val_loss: 0.9883\n",
            "Epoch 38/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.0971 - val_loss: 0.8937\n",
            "Epoch 39/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 0.9659 - val_loss: 1.5022\n",
            "Epoch 40/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 0.9489 - val_loss: 0.9018\n",
            "Epoch 41/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 0.9628 - val_loss: 0.8055\n",
            "Epoch 42/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 0.9786 - val_loss: 0.9546\n",
            "Epoch 43/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.1455 - val_loss: 1.5406\n",
            "Epoch 44/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.2661 - val_loss: 0.9255\n",
            "Epoch 45/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 0.9813 - val_loss: 0.9548\n",
            "Epoch 46/100\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 0.9211 - val_loss: 0.8452\n",
            "Epoch 46: early stopping\n",
            "MY DATA: Score for fold 5: ['loss'] of 2.3988912105560303\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_per_fold"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9340f23-b24b-4d05-f440-6a9e289fd325",
        "id": "BxEAiHL9Fpuo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.7290632724761963,\n",
              " 4.857781887054443,\n",
              " 6.990306854248047,\n",
              " 5.760232448577881,\n",
              " 2.3988912105560303]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"mean {np.mean(loss_per_fold)} and std {np.std(loss_per_fold)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9715139e-ebf2-4aeb-f7dd-5b0120f24cd2",
        "id": "YLmZ2x3NFpuo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean 4.547255134582519 and std 1.7582679961096377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-K9BsRPbFnUm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AM=0.2 and BW=0.2"
      ],
      "metadata": {
        "id": "qTcO8IFDTzxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_synthetic_array_syn_ar02=read_csv_file(csvs_syn_ar02)\n",
        "X_syn_ar02, dim_ar02=get_synthetic_data(csvs_syn_ar02, txts_syn_ar02, df_synthetic_array_syn_ar02)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "St4YwN-zVQRr",
        "outputId": "bebaaecd-69fa-424a-b575-034fc4baa398"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what merged so far:  (4840, 5801)\n",
            "what merged so far:  (9680, 5801)\n",
            "what merged so far:  (14520, 5801)\n",
            "what merged so far:  (19360, 5801)\n",
            "what merged so far:  (24200, 5801)\n",
            "what merged so far:  (29040, 5801)\n",
            "what merged so far:  (33880, 5801)\n",
            "what merged so far:  (38720, 5801)\n",
            "final merge shape (41382, 5801)\n",
            "----------------------------------------\n",
            "Time Execution: \n",
            "--- 40.53 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_scaled_syn_ar02 = scaler.transform(X_syn_ar02) \n",
        "X_scaled_real = scaler.transform(X_real) \n",
        "print(X_scaled_syn_ar02.shape)\n",
        "print(X_scaled_real.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vpZxmJNVTkT",
        "outputId": "bca8f9fa-d47f-427d-d3b9-2bfd79c99d90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(41382, 5801)\n",
            "(418, 5801)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_ar02 = np.concatenate((X_scaled_syn_ar02, X_scaled_real), axis=0)\n",
        "X_ar02 = X_ar02[..., np.newaxis] \n",
        "\n",
        "print(X_ar02.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rEl1sTYTZCs",
        "outputId": "66b8d96f-4182-4ca0-f714-becbb4d2afd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(41800, 5801, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_synthetic = ([i for i in range(4,61)]*3)*1\n",
        "y_syn = [label_synthetic[i//dim_ar02] for i in range(len(label_synthetic)*dim_ar02)]\n",
        "\n",
        "y=y_syn+y_real\n",
        "print(len(y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXiYmriRuNlM",
        "outputId": "c18fe83c-713c-4308-ec5b-16b84e2deeb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test=train_test_split(X_ar02,y, test_size=0.3, \n",
        "                                                  shuffle=True, random_state=1)\n",
        "# X_train, X_val, y_train, y_val=train_test_split(X_train,y_train, test_size=0.2, \n",
        "#                                                   shuffle=True, random_state=1)\n"
      ],
      "metadata": {
        "id": "IHbZ8GH15q8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "\n",
        "print(\"X_train:\",X_train.shape, \"y_train:\",len(y_train))\n",
        "print(\"X_test:\",X_test.shape, \"y_test:\",len(y_test))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1j8VvUpBLF-",
        "outputId": "24b8d9c0-6e3d-4ca6-e530-cd71e068d58e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (29260, 5801, 1) y_train: 29260\n",
            "X_test: (12540, 5801, 1) y_test: 12540\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "a0jVaI2hZG3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Merge inputs and targets\n",
        "inputs = np.concatenate((X_train, X_test), axis=0)\n",
        "targets = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=5, shuffle=True)\n",
        "loss_per_fold=[]\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "es = EarlyStopping(monitor='val_loss', mode='min',verbose=1, patience=5)\n",
        "\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "\n",
        "  # Define the model architecture\n",
        "  model = create_model()\n",
        "\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit(inputs[train], targets[train], validation_data=(inputs[test], targets[test]), batch_size=254, epochs =50, \n",
        "                      callbacks=[es])\n",
        "  # Generate generalization metrics\n",
        "  scores = model.evaluate(recorded_scaled, np.array(label_recorded), verbose=0)\n",
        "  # print(f'Score for fold {fold_no}: {model.metrics_names} of {scores}')\n",
        "  print(f'MY DATA: Score for fold {fold_no}: {model.metrics_names} of {scores}')\n",
        "  loss_per_fold.append(scores)\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpJQLWD1cay9",
        "outputId": "57a29512-ce9c-4e43-a7fb-57edf6e7dc53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 8s 42ms/step - loss: 7.9811 - val_loss: 2.5136\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 2.1688 - val_loss: 2.3133\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.6548 - val_loss: 1.3940\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.3652 - val_loss: 1.0291\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 1.3474 - val_loss: 1.4006\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.1414 - val_loss: 0.9127\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.0610 - val_loss: 1.2592\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.0016 - val_loss: 1.6524\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.0091 - val_loss: 1.1402\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.8948 - val_loss: 0.6978\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.8267 - val_loss: 1.3026\n",
            "Epoch 12/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.7671 - val_loss: 0.7960\n",
            "Epoch 13/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.8908 - val_loss: 0.9996\n",
            "Epoch 14/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.7325 - val_loss: 0.5771\n",
            "Epoch 15/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.8185 - val_loss: 0.6900\n",
            "Epoch 16/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.7564 - val_loss: 0.7526\n",
            "Epoch 17/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.7975 - val_loss: 0.7433\n",
            "Epoch 18/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.6281 - val_loss: 0.5549\n",
            "Epoch 19/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.6707 - val_loss: 0.6813\n",
            "Epoch 20/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.7607 - val_loss: 0.8407\n",
            "Epoch 21/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.6035 - val_loss: 0.4792\n",
            "Epoch 22/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.6441 - val_loss: 0.6272\n",
            "Epoch 23/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.5716 - val_loss: 0.9609\n",
            "Epoch 24/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.6149 - val_loss: 0.6580\n",
            "Epoch 25/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.6262 - val_loss: 0.5359\n",
            "Epoch 26/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.5522 - val_loss: 0.7707\n",
            "Epoch 26: early stopping\n",
            "MY DATA: Score for fold 1: ['loss'] of 2.6910500526428223\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 7s 40ms/step - loss: 8.7313 - val_loss: 2.7686\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 2.4299 - val_loss: 2.3307\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 1.8947 - val_loss: 1.6334\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.5231 - val_loss: 1.2820\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.3634 - val_loss: 0.9292\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.0109 - val_loss: 0.9094\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.9954 - val_loss: 0.7762\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.9745 - val_loss: 0.9553\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.8024 - val_loss: 1.1661\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.0942 - val_loss: 0.6834\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.6836 - val_loss: 0.6914\n",
            "Epoch 12/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.7857 - val_loss: 1.4554\n",
            "Epoch 13/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.7763 - val_loss: 0.9436\n",
            "Epoch 14/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.9166 - val_loss: 0.5893\n",
            "Epoch 15/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.6135 - val_loss: 0.7250\n",
            "Epoch 16/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.6746 - val_loss: 0.5956\n",
            "Epoch 17/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.7222 - val_loss: 0.5974\n",
            "Epoch 18/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.6144 - val_loss: 0.4635\n",
            "Epoch 19/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.7582 - val_loss: 0.5769\n",
            "Epoch 20/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.8198 - val_loss: 0.5428\n",
            "Epoch 21/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.5870 - val_loss: 0.6081\n",
            "Epoch 22/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.4838 - val_loss: 0.5390\n",
            "Epoch 23/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.8267 - val_loss: 0.4548\n",
            "Epoch 24/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.5870 - val_loss: 0.7164\n",
            "Epoch 25/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.5248 - val_loss: 0.4857\n",
            "Epoch 26/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.4825 - val_loss: 0.3992\n",
            "Epoch 27/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.7136 - val_loss: 0.5282\n",
            "Epoch 28/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.6817 - val_loss: 0.5365\n",
            "Epoch 29/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.4762 - val_loss: 0.4865\n",
            "Epoch 30/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.6550 - val_loss: 1.0405\n",
            "Epoch 31/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.5501 - val_loss: 0.3991\n",
            "Epoch 32/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.4988 - val_loss: 0.5228\n",
            "Epoch 33/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.5560 - val_loss: 1.3526\n",
            "Epoch 34/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.5727 - val_loss: 0.6863\n",
            "Epoch 35/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.5976 - val_loss: 0.4065\n",
            "Epoch 36/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.6276 - val_loss: 0.4230\n",
            "Epoch 36: early stopping\n",
            "MY DATA: Score for fold 2: ['loss'] of 3.6491811275482178\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 7s 40ms/step - loss: 8.8788 - val_loss: 2.3710\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.9668 - val_loss: 1.3307\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 1.2314 - val_loss: 1.3992\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 1.1694 - val_loss: 1.4291\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.9500 - val_loss: 0.9483\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 1.0021 - val_loss: 0.9599\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.0980 - val_loss: 0.8018\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.7459 - val_loss: 0.6143\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.8194 - val_loss: 0.7062\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.8142 - val_loss: 0.9391\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.7343 - val_loss: 0.5361\n",
            "Epoch 12/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.6897 - val_loss: 0.5413\n",
            "Epoch 13/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.7588 - val_loss: 0.5849\n",
            "Epoch 14/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.7077 - val_loss: 0.5423\n",
            "Epoch 15/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.7739 - val_loss: 0.8871\n",
            "Epoch 16/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.6724 - val_loss: 0.6617\n",
            "Epoch 16: early stopping\n",
            "MY DATA: Score for fold 3: ['loss'] of 2.3197333812713623\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 7s 40ms/step - loss: 6.9920 - val_loss: 3.4056\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 1.8715 - val_loss: 1.5296\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 1.3954 - val_loss: 1.2055\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 1.0777 - val_loss: 1.1356\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.0931 - val_loss: 0.7750\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.9565 - val_loss: 0.6932\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.9338 - val_loss: 0.7518\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.7564 - val_loss: 0.7980\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 1.0320 - val_loss: 0.8595\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.8591 - val_loss: 1.3301\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.6819 - val_loss: 0.6637\n",
            "Epoch 12/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.7902 - val_loss: 0.5601\n",
            "Epoch 13/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.6325 - val_loss: 0.5501\n",
            "Epoch 14/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.6271 - val_loss: 0.6404\n",
            "Epoch 15/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.6111 - val_loss: 0.6604\n",
            "Epoch 16/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.8001 - val_loss: 0.5303\n",
            "Epoch 17/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.7199 - val_loss: 0.8539\n",
            "Epoch 18/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.7293 - val_loss: 0.5791\n",
            "Epoch 19/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.5615 - val_loss: 0.5308\n",
            "Epoch 20/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.7365 - val_loss: 0.5168\n",
            "Epoch 21/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.6243 - val_loss: 0.4272\n",
            "Epoch 22/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.4919 - val_loss: 0.4773\n",
            "Epoch 23/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.5943 - val_loss: 0.8571\n",
            "Epoch 24/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.6807 - val_loss: 0.4823\n",
            "Epoch 25/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.6911 - val_loss: 0.6338\n",
            "Epoch 26/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.6651 - val_loss: 0.5213\n",
            "Epoch 26: early stopping\n",
            "MY DATA: Score for fold 4: ['loss'] of 3.2840518951416016\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 7s 40ms/step - loss: 8.5725 - val_loss: 3.3331\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 2.0413 - val_loss: 1.4472\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 1.5761 - val_loss: 1.5195\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 1.2729 - val_loss: 1.0524\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.1820 - val_loss: 0.8283\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.9845 - val_loss: 0.9142\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.2180 - val_loss: 1.5683\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.9382 - val_loss: 0.7530\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.9053 - val_loss: 0.6293\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.9168 - val_loss: 0.7587\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.7984 - val_loss: 0.6335\n",
            "Epoch 12/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.9202 - val_loss: 0.6048\n",
            "Epoch 13/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.7740 - val_loss: 1.2271\n",
            "Epoch 14/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.8428 - val_loss: 0.7784\n",
            "Epoch 15/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.7074 - val_loss: 1.5826\n",
            "Epoch 16/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.7867 - val_loss: 0.7169\n",
            "Epoch 17/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.6764 - val_loss: 0.6123\n",
            "Epoch 17: early stopping\n",
            "MY DATA: Score for fold 5: ['loss'] of 2.271413803100586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_per_fold"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVKw0sGdkIS_",
        "outputId": "49561a22-3264-47b2-f94b-45a8b4e46817"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.6910500526428223,\n",
              " 3.6491811275482178,\n",
              " 2.3197333812713623,\n",
              " 3.2840518951416016,\n",
              " 2.271413803100586]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(loss_per_fold)/len(loss_per_fold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZZipa8pkByh",
        "outputId": "8e47a544-9a75-40b6-810a-a606774fd3e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.843086051940918"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"mean {np.mean(loss_per_fold)} and std {np.std(loss_per_fold)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jceHUuiDYyXC",
        "outputId": "4fa37cc6-f65c-4e4a-b505-e7e5089d8530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean 2.843086051940918 and std 0.5418601791720292\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AM=0.3 and BW=0.3"
      ],
      "metadata": {
        "id": "9a3PlNb2pH34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_synthetic_array_syn_ar03=read_csv_file(csvs_syn_ar03)\n",
        "X_syn_ar03, dim_ar03=get_synthetic_data(csvs_syn_ar03, txts_syn_ar03, df_synthetic_array_syn_ar03)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8022dc53-dd62-46a1-f906-9b9eb7c4dfa6",
        "id": "XXMZ01jypH3-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what merged so far:  (4840, 5801)\n",
            "what merged so far:  (9680, 5801)\n",
            "what merged so far:  (14520, 5801)\n",
            "what merged so far:  (19360, 5801)\n",
            "what merged so far:  (24200, 5801)\n",
            "what merged so far:  (29040, 5801)\n",
            "what merged so far:  (33880, 5801)\n",
            "what merged so far:  (38720, 5801)\n",
            "final merge shape (41382, 5801)\n",
            "----------------------------------------\n",
            "Time Execution: \n",
            "--- 36.55 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_scaled_syn_ar03 = scaler.transform(X_syn_ar03) \n",
        "X_scaled_real = scaler.transform(X_real) \n",
        "print(X_scaled_syn_ar03.shape)\n",
        "print(X_scaled_real.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0c29a66-6b34-4fa2-ace9-4d2a4f6c39cd",
        "id": "3e7ZNeMHpH3-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(41382, 5801)\n",
            "(418, 5801)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_ar03 = np.concatenate((X_scaled_syn_ar03, X_scaled_real), axis=0)\n",
        "X_ar03 = X_ar03[..., np.newaxis] \n",
        "\n",
        "print(X_ar03.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46a3d275-c258-4950-cfab-ea740b27cb7f",
        "id": "L2VSW3UMpH3-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(41800, 5801, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_synthetic = ([i for i in range(4,61)]*3)*1\n",
        "y_syn = [label_synthetic[i//dim_ar03] for i in range(len(label_synthetic)*dim_ar03)]\n",
        "\n",
        "y=y_syn+y_real\n",
        "print(len(y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "090def39-6035-4cee-a2ce-a1581f850a19",
        "id": "Xd3MP0PYpH3-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test=train_test_split(X_ar03,y, test_size=0.3, \n",
        "                                                  shuffle=True, random_state=1)\n",
        "# X_train, X_val, y_train, y_val=train_test_split(X_train,y_train, test_size=0.2, \n",
        "#                                                   shuffle=True, random_state=1)\n"
      ],
      "metadata": {
        "id": "cO8cYQ5tpH3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "\n",
        "print(\"X_train:\",X_train.shape, \"y_train:\",len(y_train))\n",
        "print(\"X_test:\",X_test.shape, \"y_test:\",len(y_test))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13eed2f6-0bcb-4b83-82f7-58dc30ead794",
        "id": "AabkDHp2pH3-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (29260, 5801, 1) y_train: 29260\n",
            "X_test: (12540, 5801, 1) y_test: 12540\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Merge inputs and targets\n",
        "inputs = np.concatenate((X_train, X_test), axis=0)\n",
        "targets = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=5, shuffle=True)\n",
        "loss_per_fold=[]\n",
        "model_list=[]\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "es = EarlyStopping(monitor='val_loss', mode='min',verbose=1, patience=5)\n",
        "\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "\n",
        "  # Define the model architecture\n",
        "  model = create_model()\n",
        "\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit(inputs[train], targets[train], validation_data=(inputs[test], targets[test]), batch_size=254, epochs =50, \n",
        "                      callbacks=[es])\n",
        "  # Generate generalization metrics\n",
        "  scores = model.evaluate(recorded_scaled, np.array(label_recorded), verbose=0)\n",
        "  # print(f'Score for fold {fold_no}: {model.metrics_names} of {scores}')\n",
        "  print(f'MY DATA: Score for fold {fold_no}: {model.metrics_names} of {scores}')\n",
        "  loss_per_fold.append(scores)\n",
        "  model_list.append(model)\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50376b23-8ffe-454e-bf9f-e3ac6f0dcab6",
        "id": "spxUqBQIpH3_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 15s 44ms/step - loss: 5.9383 - val_loss: 1.4505\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 1.3343 - val_loss: 1.0620\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 5s 39ms/step - loss: 1.1499 - val_loss: 0.7776\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.8907 - val_loss: 0.7056\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.0338 - val_loss: 1.4196\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 1.0167 - val_loss: 0.9395\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.9140 - val_loss: 0.5747\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.6298 - val_loss: 0.5575\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.6115 - val_loss: 0.7373\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.6372 - val_loss: 0.6086\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.9119 - val_loss: 0.6713\n",
            "Epoch 12/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.5797 - val_loss: 0.4246\n",
            "Epoch 13/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.6207 - val_loss: 0.8712\n",
            "Epoch 14/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.5760 - val_loss: 0.4631\n",
            "Epoch 15/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.6277 - val_loss: 1.3634\n",
            "Epoch 16/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.5783 - val_loss: 0.5528\n",
            "Epoch 17/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.4553 - val_loss: 0.5321\n",
            "Epoch 17: early stopping\n",
            "MY DATA: Score for fold 1: ['loss'] of 3.2484452724456787\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 7s 41ms/step - loss: 5.3264 - val_loss: 1.7373\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 1.6486 - val_loss: 1.1184\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.2410 - val_loss: 1.4893\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.9278 - val_loss: 0.8218\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.8891 - val_loss: 0.9891\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 1.0091 - val_loss: 0.7191\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.9905 - val_loss: 0.6042\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.7342 - val_loss: 0.9713\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - 5s 40ms/step - loss: 0.7136 - val_loss: 0.6315\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.6918 - val_loss: 1.0357\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 1.0494 - val_loss: 1.0047\n",
            "Epoch 12/50\n",
            "132/132 [==============================] - 5s 39ms/step - loss: 0.7514 - val_loss: 0.5313\n",
            "Epoch 13/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.5538 - val_loss: 0.5320\n",
            "Epoch 14/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.6291 - val_loss: 0.5848\n",
            "Epoch 15/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.8486 - val_loss: 0.6795\n",
            "Epoch 16/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.6387 - val_loss: 0.4579\n",
            "Epoch 17/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.5280 - val_loss: 0.4941\n",
            "Epoch 18/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.8686 - val_loss: 1.2133\n",
            "Epoch 19/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.6343 - val_loss: 0.5803\n",
            "Epoch 20/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.6007 - val_loss: 0.4880\n",
            "Epoch 21/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.6651 - val_loss: 0.4357\n",
            "Epoch 22/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.5006 - val_loss: 0.4845\n",
            "Epoch 23/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.4876 - val_loss: 0.5345\n",
            "Epoch 24/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.7938 - val_loss: 0.6325\n",
            "Epoch 25/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.7120 - val_loss: 0.5206\n",
            "Epoch 26/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.5814 - val_loss: 0.5042\n",
            "Epoch 26: early stopping\n",
            "MY DATA: Score for fold 2: ['loss'] of 3.475492000579834\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 7s 40ms/step - loss: 5.3738 - val_loss: 1.9607\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 1.3307 - val_loss: 0.9659\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 1.2551 - val_loss: 0.8161\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 1.1015 - val_loss: 1.0256\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 1.0043 - val_loss: 0.9372\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.8378 - val_loss: 0.7313\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.7467 - val_loss: 0.5775\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - 5s 39ms/step - loss: 0.8474 - val_loss: 0.5495\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.7578 - val_loss: 0.6218\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - 5s 39ms/step - loss: 0.6316 - val_loss: 0.6659\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.7116 - val_loss: 0.4929\n",
            "Epoch 12/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.8511 - val_loss: 0.6554\n",
            "Epoch 13/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.5684 - val_loss: 0.5157\n",
            "Epoch 14/50\n",
            "132/132 [==============================] - 5s 39ms/step - loss: 0.8599 - val_loss: 0.4805\n",
            "Epoch 15/50\n",
            "132/132 [==============================] - 5s 39ms/step - loss: 0.6713 - val_loss: 0.6003\n",
            "Epoch 16/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.9121 - val_loss: 0.5441\n",
            "Epoch 17/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.6108 - val_loss: 0.5048\n",
            "Epoch 18/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.5857 - val_loss: 0.4174\n",
            "Epoch 19/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.5730 - val_loss: 0.6730\n",
            "Epoch 20/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.5507 - val_loss: 0.4756\n",
            "Epoch 21/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.4824 - val_loss: 0.5888\n",
            "Epoch 22/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.6927 - val_loss: 1.4445\n",
            "Epoch 23/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.6602 - val_loss: 0.4924\n",
            "Epoch 23: early stopping\n",
            "MY DATA: Score for fold 3: ['loss'] of 3.5763347148895264\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 8s 42ms/step - loss: 5.2676 - val_loss: 2.1957\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 1.7820 - val_loss: 1.3589\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 1.0781 - val_loss: 0.9104\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.9222 - val_loss: 0.7681\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 1.0313 - val_loss: 0.7443\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.8043 - val_loss: 0.7010\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.8216 - val_loss: 0.7689\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - 5s 39ms/step - loss: 0.7886 - val_loss: 0.5744\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.8246 - val_loss: 1.1542\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.7729 - val_loss: 0.5737\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.6096 - val_loss: 0.5485\n",
            "Epoch 12/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.5709 - val_loss: 0.6185\n",
            "Epoch 13/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.7601 - val_loss: 1.2497\n",
            "Epoch 14/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.5963 - val_loss: 0.4475\n",
            "Epoch 15/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.6759 - val_loss: 0.8553\n",
            "Epoch 16/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.6078 - val_loss: 1.0875\n",
            "Epoch 17/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.5374 - val_loss: 0.5018\n",
            "Epoch 18/50\n",
            "132/132 [==============================] - 5s 41ms/step - loss: 0.7634 - val_loss: 0.4985\n",
            "Epoch 19/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.4756 - val_loss: 0.6666\n",
            "Epoch 19: early stopping\n",
            "MY DATA: Score for fold 4: ['loss'] of 2.7168147563934326\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 7s 43ms/step - loss: 5.8248 - val_loss: 1.4360\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 5s 39ms/step - loss: 1.2670 - val_loss: 0.9155\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 1.3834 - val_loss: 1.1629\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 1.0139 - val_loss: 0.7277\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.8399 - val_loss: 0.7100\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.7597 - val_loss: 1.7724\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.9726 - val_loss: 0.6622\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.6704 - val_loss: 1.2060\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.6387 - val_loss: 1.7229\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.8970 - val_loss: 0.4873\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.5441 - val_loss: 0.4345\n",
            "Epoch 12/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.7138 - val_loss: 0.5005\n",
            "Epoch 13/50\n",
            "132/132 [==============================] - 5s 39ms/step - loss: 0.5038 - val_loss: 0.4729\n",
            "Epoch 14/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.6089 - val_loss: 0.4831\n",
            "Epoch 15/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.7038 - val_loss: 0.9305\n",
            "Epoch 16/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.5922 - val_loss: 0.4076\n",
            "Epoch 17/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.5089 - val_loss: 0.4925\n",
            "Epoch 18/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.4868 - val_loss: 0.4060\n",
            "Epoch 19/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.4540 - val_loss: 0.4568\n",
            "Epoch 20/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.5182 - val_loss: 0.3919\n",
            "Epoch 21/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.5310 - val_loss: 0.5158\n",
            "Epoch 22/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.4436 - val_loss: 0.4687\n",
            "Epoch 23/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.4567 - val_loss: 0.3731\n",
            "Epoch 24/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.4529 - val_loss: 0.3908\n",
            "Epoch 25/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.4731 - val_loss: 0.5259\n",
            "Epoch 26/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.4949 - val_loss: 0.4953\n",
            "Epoch 27/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.4976 - val_loss: 0.3469\n",
            "Epoch 28/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.5335 - val_loss: 0.4385\n",
            "Epoch 29/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.5723 - val_loss: 0.4465\n",
            "Epoch 30/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.4271 - val_loss: 0.3927\n",
            "Epoch 31/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.4471 - val_loss: 0.4712\n",
            "Epoch 32/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.5270 - val_loss: 0.7052\n",
            "Epoch 32: early stopping\n",
            "MY DATA: Score for fold 5: ['loss'] of 2.4289214611053467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_per_fold"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bec451e1-d256-4ccc-cec7-669649ba6865",
        "id": "XYulFg7WpH3_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.2484452724456787,\n",
              " 3.475492000579834,\n",
              " 3.5763347148895264,\n",
              " 2.7168147563934326,\n",
              " 2.4289214611053467]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(loss_per_fold)/len(loss_per_fold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "307d4fcf-bd39-45f5-c346-26e1d38009a6",
        "id": "qNSU2l4TpH3_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.089201641082764"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"mean: {np.mean(loss_per_fold)} and std: {np.std(loss_per_fold)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UNxuYaqFV_u",
        "outputId": "d37c6f0d-6dc5-4925-c175-78111e0f111c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean: 3.089201641082764 and std: 0.4441889948042576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AM=0.4 and BW=0.4"
      ],
      "metadata": {
        "id": "x7e8WZ2yt_Bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_synthetic_array_syn_ar04=read_csv_file(csvs_syn_ar04)\n",
        "X_syn_ar04, dim_ar04=get_synthetic_data(csvs_syn_ar04, txts_syn_ar04, df_synthetic_array_syn_ar04)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6862af5-f8db-46f8-a8c6-d0f961fb0a56",
        "id": "fhPjofzUt_Bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what merged so far:  (4840, 5801)\n",
            "what merged so far:  (9680, 5801)\n",
            "what merged so far:  (14520, 5801)\n",
            "what merged so far:  (19360, 5801)\n",
            "what merged so far:  (24200, 5801)\n",
            "what merged so far:  (29040, 5801)\n",
            "what merged so far:  (33880, 5801)\n",
            "what merged so far:  (38720, 5801)\n",
            "final merge shape (41382, 5801)\n",
            "----------------------------------------\n",
            "Time Execution: \n",
            "--- 40.15 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_scaled_syn_ar04 = scaler.transform(X_syn_ar04) \n",
        "X_scaled_real = scaler.transform(X_real) \n",
        "print(X_scaled_syn_ar04.shape)\n",
        "print(X_scaled_real.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cb2e4b1-d322-4dc6-8ef7-cbbcbb8485a0",
        "id": "s-Ll_Rrzt_Bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(41382, 5801)\n",
            "(418, 5801)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_ar04 = np.concatenate((X_scaled_syn_ar04, X_scaled_real), axis=0)\n",
        "X_ar04 = X_ar04[..., np.newaxis] \n",
        "\n",
        "print(X_ar04.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76d86ffa-0d64-49d9-b454-1829706df5e0",
        "id": "MFDhXK0Ct_Bg"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(41800, 5801, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_synthetic = ([i for i in range(4,61)]*3)*1\n",
        "y_syn = [label_synthetic[i//dim_ar04] for i in range(len(label_synthetic)*dim_ar04)]\n",
        "\n",
        "y=y_syn+y_real\n",
        "print(len(y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24e8e75a-4621-44d7-89ca-07732823b472",
        "id": "uM-xwOEnt_Bg"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test=train_test_split(X_ar04,y, test_size=0.3, \n",
        "                                                  shuffle=True, random_state=1)\n",
        "# X_train, X_val, y_train, y_val=train_test_split(X_train,y_train, test_size=0.2, \n",
        "#                                                   shuffle=True, random_state=1)\n"
      ],
      "metadata": {
        "id": "qmM5ppUct_Bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "\n",
        "print(\"X_train:\",X_train.shape, \"y_train:\",len(y_train))\n",
        "print(\"X_test:\",X_test.shape, \"y_test:\",len(y_test))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "276995e3-1261-4aeb-cdb8-ffd04cb9c1e6",
        "id": "S-ANcJQ4t_Bg"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (29260, 5801, 1) y_train: 29260\n",
            "X_test: (12540, 5801, 1) y_test: 12540\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Merge inputs and targets\n",
        "inputs = np.concatenate((X_train, X_test), axis=0)\n",
        "targets = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=5, shuffle=True)\n",
        "loss_per_fold=[]\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "es = EarlyStopping(monitor='val_loss', mode='min',verbose=1, patience=5)\n",
        "\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "\n",
        "  # Define the model architecture\n",
        "  model = create_model()\n",
        "\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit(inputs[train], targets[train], validation_data=(inputs[test], targets[test]), batch_size=254, epochs =50, \n",
        "                      callbacks=[es])\n",
        "  # Generate generalization metrics\n",
        "  scores = model.evaluate(recorded_scaled, np.array(label_recorded), verbose=0)\n",
        "  # print(f'Score for fold {fold_no}: {model.metrics_names} of {scores}')\n",
        "  print(f'MY DATA: Score for fold {fold_no}: {model.metrics_names} of {scores}')\n",
        "  loss_per_fold.append(scores)\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51323e57-c41a-4bc7-c1a5-f9077ae39d68",
        "id": "-5WmsrTOt_Bg"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 8s 43ms/step - loss: 5.6259 - val_loss: 2.6269\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 1.5642 - val_loss: 1.3076\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 1.1016 - val_loss: 1.1559\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.9614 - val_loss: 0.8543\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.8861 - val_loss: 0.6881\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.7862 - val_loss: 0.6879\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.6854 - val_loss: 0.6437\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.7626 - val_loss: 0.5855\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.8575 - val_loss: 1.2404\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.6076 - val_loss: 0.6674\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.6427 - val_loss: 0.4741\n",
            "Epoch 12/50\n",
            "132/132 [==============================] - 5s 40ms/step - loss: 0.5669 - val_loss: 0.6432\n",
            "Epoch 13/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.4882 - val_loss: 0.7327\n",
            "Epoch 14/50\n",
            "132/132 [==============================] - 5s 39ms/step - loss: 0.7198 - val_loss: 0.4981\n",
            "Epoch 15/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.6337 - val_loss: 0.7340\n",
            "Epoch 16/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.6352 - val_loss: 0.5446\n",
            "Epoch 16: early stopping\n",
            "MY DATA: Score for fold 1: ['loss'] of 2.5298235416412354\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 7s 42ms/step - loss: 6.3699 - val_loss: 1.6135\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 1.3294 - val_loss: 1.0007\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.9900 - val_loss: 1.3417\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.8610 - val_loss: 0.8144\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.8034 - val_loss: 0.7619\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.9436 - val_loss: 0.9927\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.8481 - val_loss: 0.9856\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.7094 - val_loss: 0.5872\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.6532 - val_loss: 0.4830\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.6395 - val_loss: 1.1663\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.7334 - val_loss: 0.5340\n",
            "Epoch 12/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.5957 - val_loss: 0.4167\n",
            "Epoch 13/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.5420 - val_loss: 0.4892\n",
            "Epoch 14/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.6125 - val_loss: 0.4039\n",
            "Epoch 15/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.4970 - val_loss: 0.4102\n",
            "Epoch 16/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.5856 - val_loss: 0.4314\n",
            "Epoch 17/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.5249 - val_loss: 0.4366\n",
            "Epoch 18/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.5456 - val_loss: 0.4123\n",
            "Epoch 19/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.5178 - val_loss: 0.5619\n",
            "Epoch 19: early stopping\n",
            "MY DATA: Score for fold 2: ['loss'] of 16.902530670166016\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 8s 41ms/step - loss: 5.1376 - val_loss: 1.5361\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 1.4486 - val_loss: 1.1589\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 1.2016 - val_loss: 1.3744\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 1.1183 - val_loss: 1.6112\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.8711 - val_loss: 0.6646\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.8343 - val_loss: 0.8617\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 1.0941 - val_loss: 0.9639\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.7120 - val_loss: 0.5279\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.7363 - val_loss: 0.5670\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.6386 - val_loss: 0.7282\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.6013 - val_loss: 1.3760\n",
            "Epoch 12/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.6943 - val_loss: 1.0208\n",
            "Epoch 13/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.5657 - val_loss: 0.5633\n",
            "Epoch 13: early stopping\n",
            "MY DATA: Score for fold 3: ['loss'] of 2.4684245586395264\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 7s 40ms/step - loss: 5.6657 - val_loss: 1.7639\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 1.4823 - val_loss: 1.2354\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 1.0034 - val_loss: 0.8893\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.8711 - val_loss: 0.9036\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.8328 - val_loss: 0.9631\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.7471 - val_loss: 0.6986\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.9332 - val_loss: 0.7308\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.6871 - val_loss: 0.7848\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.7678 - val_loss: 0.9630\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.5682 - val_loss: 0.4743\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.5746 - val_loss: 0.6058\n",
            "Epoch 12/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.5731 - val_loss: 0.5710\n",
            "Epoch 13/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.5049 - val_loss: 1.0086\n",
            "Epoch 14/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.6917 - val_loss: 0.4100\n",
            "Epoch 15/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.5642 - val_loss: 0.4359\n",
            "Epoch 16/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.6956 - val_loss: 0.8491\n",
            "Epoch 17/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.5788 - val_loss: 0.3810\n",
            "Epoch 18/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.5641 - val_loss: 0.6826\n",
            "Epoch 19/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.5283 - val_loss: 1.0224\n",
            "Epoch 20/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.4561 - val_loss: 0.4391\n",
            "Epoch 21/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.4426 - val_loss: 0.4390\n",
            "Epoch 22/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.5541 - val_loss: 0.4237\n",
            "Epoch 22: early stopping\n",
            "MY DATA: Score for fold 4: ['loss'] of 2.6180713176727295\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 7s 41ms/step - loss: 5.3236 - val_loss: 1.4577\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.5904 - val_loss: 1.2214\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 1.0168 - val_loss: 1.2052\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 1.0179 - val_loss: 0.9126\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 1.2002 - val_loss: 0.6461\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.7662 - val_loss: 0.6088\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.8432 - val_loss: 0.9988\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.6969 - val_loss: 0.6375\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.6021 - val_loss: 0.7150\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.9743 - val_loss: 0.5776\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.5960 - val_loss: 0.6268\n",
            "Epoch 12/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.5511 - val_loss: 0.5257\n",
            "Epoch 13/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.7008 - val_loss: 0.6736\n",
            "Epoch 14/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.6690 - val_loss: 0.6899\n",
            "Epoch 15/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.5856 - val_loss: 0.5322\n",
            "Epoch 16/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.5582 - val_loss: 0.4316\n",
            "Epoch 17/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.4986 - val_loss: 1.1425\n",
            "Epoch 18/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.7134 - val_loss: 0.4533\n",
            "Epoch 19/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.6140 - val_loss: 0.5720\n",
            "Epoch 20/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.5555 - val_loss: 0.5767\n",
            "Epoch 21/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.5275 - val_loss: 0.6533\n",
            "Epoch 21: early stopping\n",
            "MY DATA: Score for fold 5: ['loss'] of 3.422086238861084\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_per_fold"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2d34cd8-fd26-4346-d5a1-2624305217bd",
        "id": "hopHJU2wt_Bh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.5298235416412354,\n",
              " 16.902530670166016,\n",
              " 2.4684245586395264,\n",
              " 2.6180713176727295,\n",
              " 3.422086238861084]"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"mean {np.mean(loss_per_fold)} and std {np.std(loss_per_fold)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cd4214d-4273-41c0-a3a5-639cb7dd409e",
        "id": "8G8zHHyct_Bh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean 5.588187265396118 and std 5.66770601027234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "S-cf1s5Z5YpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FM = 0.03"
      ],
      "metadata": {
        "id": "INUt4C0_5Ywo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_synthetic_array_syn_arfm3=read_csv_file(csvs_syn_arfm3)\n",
        "X_syn_arfm3, dim_arfm3=get_synthetic_data(csvs_syn_arfm3, txts_syn_arfm3, df_synthetic_array_syn_arfm3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19fdefec-e4ec-4b6e-f242-c69f97937d1b",
        "id": "LtJdumAW5Ywo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what merged so far:  (4840, 5801)\n",
            "what merged so far:  (9680, 5801)\n",
            "what merged so far:  (14520, 5801)\n",
            "what merged so far:  (19360, 5801)\n",
            "what merged so far:  (24200, 5801)\n",
            "what merged so far:  (29040, 5801)\n",
            "what merged so far:  (33880, 5801)\n",
            "what merged so far:  (38720, 5801)\n",
            "final merge shape (41382, 5801)\n",
            "----------------------------------------\n",
            "Time Execution: \n",
            "--- 36.24 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_scaled_syn_arfm3 = scaler.transform(X_syn_arfm3) \n",
        "X_scaled_real = scaler.transform(X_real) \n",
        "print(X_scaled_syn_arfm3.shape)\n",
        "print(X_scaled_real.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78cce8d4-b229-4c68-de56-b3ae9b0fe53e",
        "id": "3ngoKFzw5Ywo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(41382, 5801)\n",
            "(418, 5801)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_arfm3 = np.concatenate((X_scaled_syn_arfm3, X_scaled_real), axis=0)\n",
        "X_arfm3 = X_arfm3[..., np.newaxis] \n",
        "\n",
        "print(X_arfm3.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe3d5b03-5873-422c-e61f-6afe7ca03e64",
        "id": "vetJ2Hi75Ywo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(41800, 5801, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_synthetic = ([i for i in range(4,61)]*3)*1\n",
        "y_syn = [label_synthetic[i//dim_arfm3] for i in range(len(label_synthetic)*dim_arfm3)]\n",
        "\n",
        "y=y_syn+y_real\n",
        "print(len(y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17c83b04-60f7-4e8e-b858-fd68b1edc84f",
        "id": "IN1BFi5c5Ywp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test=train_test_split(X_arfm3,y, test_size=0.3, \n",
        "                                                  shuffle=True, random_state=1)\n",
        "# X_train, X_val, y_train, y_val=train_test_split(X_train,y_train, test_size=0.2, \n",
        "#                                                   shuffle=True, random_state=1)\n"
      ],
      "metadata": {
        "id": "3RVM6O9M5Ywp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "\n",
        "print(\"X_train:\",X_train.shape, \"y_train:\",len(y_train))\n",
        "print(\"X_test:\",X_test.shape, \"y_test:\",len(y_test))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b065a6a-ab93-4017-d511-0cdd6c2364f8",
        "id": "bAUzLigA5Ywp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (29260, 5801, 1) y_train: 29260\n",
            "X_test: (12540, 5801, 1) y_test: 12540\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Merge inputs and targets\n",
        "inputs = np.concatenate((X_train, X_test), axis=0)\n",
        "targets = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=5, shuffle=True)\n",
        "loss_per_fold=[]\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "es = EarlyStopping(monitor='val_loss', mode='min',verbose=1, patience=5)\n",
        "\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "\n",
        "  # Define the model architecture\n",
        "  model = create_model()\n",
        "\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit(inputs[train], targets[train], validation_data=(inputs[test], targets[test]), batch_size=254, epochs =50, \n",
        "                      callbacks=[es])\n",
        "  # Generate generalization metrics\n",
        "  scores = model.evaluate(recorded_scaled, np.array(label_recorded), verbose=0)\n",
        "  # print(f'Score for fold {fold_no}: {model.metrics_names} of {scores}')\n",
        "  print(f'MY DATA: Score for fold {fold_no}: {model.metrics_names} of {scores}')\n",
        "  loss_per_fold.append(scores)\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5780d24-fc2d-4ebf-c473-b1fe996bcfff",
        "id": "eheY3vhr5Ywp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 15s 43ms/step - loss: 31.7884 - val_loss: 31.8833\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8503 - val_loss: 31.8833\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8503 - val_loss: 31.8833\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8503 - val_loss: 31.8833\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 31.8503 - val_loss: 31.8833\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8503 - val_loss: 31.8833\n",
            "Epoch 6: early stopping\n",
            "MY DATA: Score for fold 1: ['loss'] of 15.188679695129395\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 7s 40ms/step - loss: 11.6083 - val_loss: 6.2451\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 3.4431 - val_loss: 2.5268\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 2.0680 - val_loss: 1.6724\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.6858 - val_loss: 1.6167\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.5903 - val_loss: 1.5847\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.2915 - val_loss: 1.8439\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.2768 - val_loss: 1.4423\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.2931 - val_loss: 1.1969\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 1.4529 - val_loss: 1.1393\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.1272 - val_loss: 0.9238\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.0286 - val_loss: 0.9353\n",
            "Epoch 12/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.3409 - val_loss: 0.9851\n",
            "Epoch 13/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 1.2040 - val_loss: 0.9648\n",
            "Epoch 14/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.8787 - val_loss: 0.7853\n",
            "Epoch 15/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.9914 - val_loss: 0.7633\n",
            "Epoch 16/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.8653 - val_loss: 1.2301\n",
            "Epoch 17/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.1309 - val_loss: 1.1253\n",
            "Epoch 18/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.8558 - val_loss: 0.8209\n",
            "Epoch 19/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.0758 - val_loss: 1.0749\n",
            "Epoch 20/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.0094 - val_loss: 0.9069\n",
            "Epoch 20: early stopping\n",
            "MY DATA: Score for fold 2: ['loss'] of 3.8072803020477295\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 7s 40ms/step - loss: 31.8672 - val_loss: 31.8157\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8672 - val_loss: 31.8157\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8672 - val_loss: 31.8157\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8672 - val_loss: 31.8157\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8672 - val_loss: 31.8157\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8672 - val_loss: 31.8157\n",
            "Epoch 6: early stopping\n",
            "MY DATA: Score for fold 3: ['loss'] of 15.188679695129395\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 7s 40ms/step - loss: 12.2794 - val_loss: 8.5068\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 6.8559 - val_loss: 5.7386\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 5.6295 - val_loss: 5.5873\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 5.1455 - val_loss: 3.4638\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 3.4534 - val_loss: 2.2040\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 2.0216 - val_loss: 1.6827\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 1.8907 - val_loss: 1.9338\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.5730 - val_loss: 2.1216\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.6777 - val_loss: 1.6722\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.1730 - val_loss: 1.0389\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.1858 - val_loss: 1.1788\n",
            "Epoch 12/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.0555 - val_loss: 0.9962\n",
            "Epoch 13/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.9730 - val_loss: 0.9106\n",
            "Epoch 14/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.3888 - val_loss: 1.6851\n",
            "Epoch 15/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.3130 - val_loss: 1.1519\n",
            "Epoch 16/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.9935 - val_loss: 1.1903\n",
            "Epoch 17/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.0094 - val_loss: 0.7230\n",
            "Epoch 18/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.8630 - val_loss: 0.7009\n",
            "Epoch 19/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.7696 - val_loss: 0.7311\n",
            "Epoch 20/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.9519 - val_loss: 0.9017\n",
            "Epoch 21/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.8052 - val_loss: 0.6320\n",
            "Epoch 22/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.2232 - val_loss: 0.9598\n",
            "Epoch 23/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.8574 - val_loss: 0.6973\n",
            "Epoch 24/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.7814 - val_loss: 1.0874\n",
            "Epoch 25/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.7775 - val_loss: 0.6512\n",
            "Epoch 26/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.7823 - val_loss: 0.6814\n",
            "Epoch 26: early stopping\n",
            "MY DATA: Score for fold 4: ['loss'] of 3.699939727783203\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 7s 40ms/step - loss: 11.6831 - val_loss: 5.9171\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 4.2023 - val_loss: 2.0623\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 2.0624 - val_loss: 1.5099\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.5370 - val_loss: 1.2893\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.2805 - val_loss: 1.1998\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.1728 - val_loss: 0.9906\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.0757 - val_loss: 0.9359\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 1.1339 - val_loss: 1.0578\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.0529 - val_loss: 0.8906\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.0318 - val_loss: 1.0462\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.8989 - val_loss: 0.9388\n",
            "Epoch 12/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.9619 - val_loss: 1.4663\n",
            "Epoch 13/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.9353 - val_loss: 0.8364\n",
            "Epoch 14/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.8649 - val_loss: 0.7243\n",
            "Epoch 15/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.9843 - val_loss: 0.7177\n",
            "Epoch 16/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.9023 - val_loss: 0.7785\n",
            "Epoch 17/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.7426 - val_loss: 0.7204\n",
            "Epoch 18/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.8374 - val_loss: 0.7123\n",
            "Epoch 19/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.7547 - val_loss: 0.6602\n",
            "Epoch 20/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.8023 - val_loss: 0.7967\n",
            "Epoch 21/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.7242 - val_loss: 0.5949\n",
            "Epoch 22/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.7963 - val_loss: 1.8586\n",
            "Epoch 23/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.7734 - val_loss: 0.8837\n",
            "Epoch 24/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.6947 - val_loss: 0.6296\n",
            "Epoch 25/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.6845 - val_loss: 0.6453\n",
            "Epoch 26/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.8072 - val_loss: 0.6534\n",
            "Epoch 26: early stopping\n",
            "MY DATA: Score for fold 5: ['loss'] of 4.07932710647583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_per_fold"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d64dad41-266b-4654-de36-0526d2069df1",
        "id": "pWtwVxh_5Ywp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[15.188679695129395,\n",
              " 3.8072803020477295,\n",
              " 15.188679695129395,\n",
              " 3.699939727783203,\n",
              " 4.07932710647583]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"mean {np.mean(loss_per_fold)} and std {np.std(loss_per_fold)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b99e2a99-6f2f-47ac-c767-8f8066a8514e",
        "id": "VeetBaka5Ywp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean 8.392781305313111 and std 5.550206095229677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7flYn4WWJZa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FM = 0.025"
      ],
      "metadata": {
        "id": "W4jFa_fYJZhU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_synthetic_array_syn_arfm4=read_csv_file(csvs_syn_arfm4)\n",
        "X_syn_arfm4, dim_arfm4=get_synthetic_data(csvs_syn_arfm4, txts_syn_arfm4, df_synthetic_array_syn_arfm4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c80fcd7c-b4b2-4d4e-94ad-9c25b524c72e",
        "id": "uvvwz9U_JZhV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what merged so far:  (4840, 5801)\n",
            "what merged so far:  (9680, 5801)\n",
            "what merged so far:  (14520, 5801)\n",
            "what merged so far:  (19360, 5801)\n",
            "what merged so far:  (24200, 5801)\n",
            "what merged so far:  (29040, 5801)\n",
            "what merged so far:  (33880, 5801)\n",
            "what merged so far:  (38720, 5801)\n",
            "final merge shape (41382, 5801)\n",
            "----------------------------------------\n",
            "Time Execution: \n",
            "--- 39.67 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_scaled_syn_arfm4 = scaler.transform(X_syn_arfm4) \n",
        "X_scaled_real = scaler.transform(X_real) \n",
        "print(X_scaled_syn_arfm4.shape)\n",
        "print(X_scaled_real.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cf56742-8d34-4926-d476-260a96c5cecd",
        "id": "rUQimYT4JZhV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(41382, 5801)\n",
            "(418, 5801)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_arfm4 = np.concatenate((X_scaled_syn_arfm4, X_scaled_real), axis=0)\n",
        "X_arfm4 = X_arfm4[..., np.newaxis] \n",
        "\n",
        "print(X_arfm4.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97f863f7-2c22-47e4-d8be-c20aae0c715b",
        "id": "53k6dgbIJZhV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(41800, 5801, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_synthetic = ([i for i in range(4,61)]*3)*1\n",
        "y_syn = [label_synthetic[i//dim_arfm4] for i in range(len(label_synthetic)*dim_arfm4)]\n",
        "\n",
        "y=y_syn+y_real\n",
        "print(len(y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfd60092-346a-4c28-c06a-b5d8eb6f23e1",
        "id": "2UO8atCnJZhV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test=train_test_split(X_arfm4,y, test_size=0.3, \n",
        "                                                  shuffle=True, random_state=1)\n",
        "# X_train, X_val, y_train, y_val=train_test_split(X_train,y_train, test_size=0.2, \n",
        "#                                                   shuffle=True, random_state=1)\n"
      ],
      "metadata": {
        "id": "YnlLghNYJZhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "\n",
        "print(\"X_train:\",X_train.shape, \"y_train:\",len(y_train))\n",
        "print(\"X_test:\",X_test.shape, \"y_test:\",len(y_test))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "723151b8-2fa7-42d1-c91d-5b5de868ce52",
        "id": "p_acoJ0kJZhV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (29260, 5801, 1) y_train: 29260\n",
            "X_test: (12540, 5801, 1) y_test: 12540\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Merge inputs and targets\n",
        "inputs = np.concatenate((X_train, X_test), axis=0)\n",
        "targets = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=5, shuffle=True)\n",
        "loss_per_fold=[]\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "es = EarlyStopping(monitor='val_loss', mode='min',verbose=1, patience=5)\n",
        "\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "\n",
        "  # Define the model architecture\n",
        "  model = create_model()\n",
        "\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit(inputs[train], targets[train], validation_data=(inputs[test], targets[test]), batch_size=254, epochs =50, \n",
        "                      callbacks=[es])\n",
        "  # Generate generalization metrics\n",
        "  scores = model.evaluate(recorded_scaled, np.array(label_recorded), verbose=0)\n",
        "  # print(f'Score for fold {fold_no}: {model.metrics_names} of {scores}')\n",
        "  print(f'MY DATA: Score for fold {fold_no}: {model.metrics_names} of {scores}')\n",
        "  loss_per_fold.append(scores)\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c104c237-6cea-453b-b8a4-b95a531584ea",
        "id": "Zvty1d_EJZhW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 7s 41ms/step - loss: 32.1440 - val_loss: 31.7957\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8722 - val_loss: 31.7957\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8722 - val_loss: 31.7957\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8722 - val_loss: 31.7957\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8722 - val_loss: 31.7957\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8722 - val_loss: 31.7957\n",
            "Epoch 6: early stopping\n",
            "MY DATA: Score for fold 1: ['loss'] of 15.188679695129395\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 8s 45ms/step - loss: 11.5237 - val_loss: 6.5909\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 4.0165 - val_loss: 2.8013\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 2.4016 - val_loss: 1.8578\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.9350 - val_loss: 2.3644\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.6247 - val_loss: 1.2487\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.5064 - val_loss: 1.5534\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.5762 - val_loss: 1.0918\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.2425 - val_loss: 1.8727\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.2004 - val_loss: 1.0844\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.0098 - val_loss: 1.1376\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.9978 - val_loss: 0.8915\n",
            "Epoch 12/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.0442 - val_loss: 1.3075\n",
            "Epoch 13/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.9106 - val_loss: 0.8031\n",
            "Epoch 14/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.9923 - val_loss: 0.8037\n",
            "Epoch 15/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.3982 - val_loss: 1.3032\n",
            "Epoch 16/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.9798 - val_loss: 0.8679\n",
            "Epoch 17/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.9058 - val_loss: 0.8146\n",
            "Epoch 18/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.8284 - val_loss: 0.9224\n",
            "Epoch 18: early stopping\n",
            "MY DATA: Score for fold 2: ['loss'] of 6.996931552886963\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 7s 40ms/step - loss: 12.8844 - val_loss: 7.0530\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 6.0695 - val_loss: 5.5933\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 3.6838 - val_loss: 2.7969\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.9493 - val_loss: 2.1232\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.6899 - val_loss: 1.3736\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.6139 - val_loss: 1.7897\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.3475 - val_loss: 1.4237\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.3947 - val_loss: 2.9878\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.4513 - val_loss: 1.1670\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.0671 - val_loss: 0.9317\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.0736 - val_loss: 0.9218\n",
            "Epoch 12/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.0973 - val_loss: 0.8580\n",
            "Epoch 13/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.9297 - val_loss: 1.4366\n",
            "Epoch 14/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.9454 - val_loss: 1.3282\n",
            "Epoch 15/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.9465 - val_loss: 0.8666\n",
            "Epoch 16/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.0924 - val_loss: 1.0991\n",
            "Epoch 17/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.8365 - val_loss: 0.8539\n",
            "Epoch 18/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.8626 - val_loss: 0.8597\n",
            "Epoch 19/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.8644 - val_loss: 1.7938\n",
            "Epoch 20/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.9611 - val_loss: 1.5526\n",
            "Epoch 21/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.8803 - val_loss: 1.1888\n",
            "Epoch 22/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.8088 - val_loss: 0.7517\n",
            "Epoch 23/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.8820 - val_loss: 1.3810\n",
            "Epoch 24/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.8485 - val_loss: 0.5855\n",
            "Epoch 25/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.7320 - val_loss: 1.1356\n",
            "Epoch 26/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.7150 - val_loss: 0.5956\n",
            "Epoch 27/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.9107 - val_loss: 0.6651\n",
            "Epoch 28/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.6439 - val_loss: 0.7148\n",
            "Epoch 29/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.7121 - val_loss: 0.6162\n",
            "Epoch 29: early stopping\n",
            "MY DATA: Score for fold 3: ['loss'] of 3.2668652534484863\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 7s 41ms/step - loss: 12.6153 - val_loss: 5.8236\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 4.7075 - val_loss: 2.6496\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 2.6797 - val_loss: 1.9313\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.6507 - val_loss: 1.3685\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.7924 - val_loss: 1.4866\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.4004 - val_loss: 1.2862\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.1812 - val_loss: 1.1434\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 1.1421 - val_loss: 0.9841\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.1287 - val_loss: 1.1030\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.0177 - val_loss: 0.8527\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.0365 - val_loss: 1.8167\n",
            "Epoch 12/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 1.3651 - val_loss: 0.9201\n",
            "Epoch 13/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.9796 - val_loss: 1.3435\n",
            "Epoch 14/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.9740 - val_loss: 1.4134\n",
            "Epoch 15/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 0.9000 - val_loss: 1.1539\n",
            "Epoch 15: early stopping\n",
            "MY DATA: Score for fold 4: ['loss'] of 4.9630818367004395\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 7s 41ms/step - loss: 31.9586 - val_loss: 31.2104\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 32.0185 - val_loss: 31.2104\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 32.0185 - val_loss: 31.2104\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 32.0185 - val_loss: 31.2104\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 32.0185 - val_loss: 31.2104\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 32.0185 - val_loss: 31.2104\n",
            "Epoch 6: early stopping\n",
            "MY DATA: Score for fold 5: ['loss'] of 15.188679695129395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_per_fold"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c70a1d05-8044-4d19-ac6d-a228e6bc0396",
        "id": "DI7nVM3TJZhW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[15.188679695129395,\n",
              " 6.996931552886963,\n",
              " 3.2668652534484863,\n",
              " 4.9630818367004395,\n",
              " 15.188679695129395]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"mean {np.mean(loss_per_fold)} and std {np.std(loss_per_fold)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a308077-c21f-4dce-e1a6-c988e68d2ff5",
        "id": "KQV29xnbJZhW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean 9.120847606658936 and std 5.093217401618583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wimaf76-P2R4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## General Amplitude = 3"
      ],
      "metadata": {
        "id": "6FECUgtvP2vY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_synthetic_array_syn_range3=read_csv_file(csvs_syn_range3)\n",
        "X_syn_range3, dim_range3=get_synthetic_data(csvs_syn_range3, txts_syn_range3, df_synthetic_array_syn_range3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "704555bb-e26b-4309-9942-cb5f5e92c5ae",
        "id": "VChpDLPtP2vZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what merged so far:  (4840, 5801)\n",
            "what merged so far:  (9680, 5801)\n",
            "what merged so far:  (14520, 5801)\n",
            "what merged so far:  (19360, 5801)\n",
            "what merged so far:  (24200, 5801)\n",
            "what merged so far:  (29040, 5801)\n",
            "what merged so far:  (33880, 5801)\n",
            "what merged so far:  (38720, 5801)\n",
            "final merge shape (41382, 5801)\n",
            "----------------------------------------\n",
            "Time Execution: \n",
            "--- 37.02 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_scaled_syn_range3 = scaler.transform(X_syn_range3) \n",
        "X_scaled_real = scaler.transform(X_real) \n",
        "print(X_scaled_syn_range3.shape)\n",
        "print(X_scaled_real.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8e2ae5b-102a-4254-9c46-b8583d563da1",
        "id": "XAoUu9nyP2vZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(41382, 5801)\n",
            "(418, 5801)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_range3 = np.concatenate((X_scaled_syn_range3, X_scaled_real), axis=0)\n",
        "X_range3 = X_range3[..., np.newaxis] \n",
        "\n",
        "print(X_range3.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c08e91d-26e2-4263-b2e8-26c7fbd5c898",
        "id": "h8i_5xZMP2vZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(41800, 5801, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_synthetic = ([i for i in range(4,61)]*3)*1\n",
        "y_syn = [label_synthetic[i//dim_range3] for i in range(len(label_synthetic)*dim_range3)]\n",
        "\n",
        "y=y_syn+y_real\n",
        "print(len(y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77c6af03-adbb-4850-ab95-2e259fcfbed6",
        "id": "XNwFFpIdP2vZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test=train_test_split(X_range3,y, test_size=0.3, \n",
        "                                                  shuffle=True, random_state=1)\n",
        "# X_train, X_val, y_train, y_val=train_test_split(X_train,y_train, test_size=0.2, \n",
        "#                                                   shuffle=True, random_state=1)\n"
      ],
      "metadata": {
        "id": "CihGlGjUP2va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "\n",
        "print(\"X_train:\",X_train.shape, \"y_train:\",len(y_train))\n",
        "print(\"X_test:\",X_test.shape, \"y_test:\",len(y_test))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9f5cc32-1f67-4fc4-a80c-31aad4258dcb",
        "id": "rBjhXG5RP2va"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (29260, 5801, 1) y_train: 29260\n",
            "X_test: (12540, 5801, 1) y_test: 12540\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Merge inputs and targets\n",
        "inputs = np.concatenate((X_train, X_test), axis=0)\n",
        "targets = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=5, shuffle=True)\n",
        "loss_per_fold=[]\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "es = EarlyStopping(monitor='val_loss', mode='min',verbose=1, patience=5)\n",
        "\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "\n",
        "  # Define the model architecture\n",
        "  model = create_model()\n",
        "\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit(inputs[train], targets[train], validation_data=(inputs[test], targets[test]), batch_size=254, epochs =50, \n",
        "                      callbacks=[es])\n",
        "  # Generate generalization metrics\n",
        "  scores = model.evaluate(recorded_scaled, np.array(label_recorded), verbose=0)\n",
        "  # print(f'Score for fold {fold_no}: {model.metrics_names} of {scores}')\n",
        "  print(f'MY DATA: Score for fold {fold_no}: {model.metrics_names} of {scores}')\n",
        "  loss_per_fold.append(scores)\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bfafdaf-34e7-4982-a039-27e2e6fbc87c",
        "id": "5JWvuFMRP2vb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 12s 44ms/step - loss: 31.8223 - val_loss: 31.9768\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 31.8269 - val_loss: 31.9768\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8269 - val_loss: 31.9768\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8269 - val_loss: 31.9768\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8269 - val_loss: 31.9768\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8269 - val_loss: 31.9768\n",
            "Epoch 6: early stopping\n",
            "MY DATA: Score for fold 1: ['loss'] of 15.188679695129395\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 7s 40ms/step - loss: 31.9796 - val_loss: 31.8330\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8629 - val_loss: 31.8330\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8629 - val_loss: 31.8330\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8629 - val_loss: 31.8330\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8629 - val_loss: 31.8330\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8629 - val_loss: 31.8330\n",
            "Epoch 6: early stopping\n",
            "MY DATA: Score for fold 2: ['loss'] of 15.188679695129395\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 7s 40ms/step - loss: 31.7952 - val_loss: 31.9992\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8213 - val_loss: 31.9992\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8213 - val_loss: 31.9992\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8213 - val_loss: 31.9992\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8213 - val_loss: 31.9992\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8213 - val_loss: 31.9992\n",
            "Epoch 6: early stopping\n",
            "MY DATA: Score for fold 3: ['loss'] of 15.188679695129395\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 7s 40ms/step - loss: 31.8602 - val_loss: 31.7251\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8898 - val_loss: 31.7251\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8898 - val_loss: 31.7251\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 31.8898 - val_loss: 31.7251\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8898 - val_loss: 31.7251\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8898 - val_loss: 31.7251\n",
            "Epoch 6: early stopping\n",
            "MY DATA: Score for fold 4: ['loss'] of 15.188679695129395\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 7s 40ms/step - loss: 31.8792 - val_loss: 31.7504\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8835 - val_loss: 31.7504\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8835 - val_loss: 31.7504\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8835 - val_loss: 31.7504\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8835 - val_loss: 31.7504\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8835 - val_loss: 31.7504\n",
            "Epoch 6: early stopping\n",
            "MY DATA: Score for fold 5: ['loss'] of 15.188679695129395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_per_fold"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "557d12f6-5600-471e-d135-1fdbbebdd38a",
        "id": "MUbdqu06P2vc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[15.188679695129395,\n",
              " 15.188679695129395,\n",
              " 15.188679695129395,\n",
              " 15.188679695129395,\n",
              " 15.188679695129395]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"mean {np.mean(loss_per_fold)} and std {np.std(loss_per_fold)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77bec346-cac7-42a6-d6de-df00c4058aa1",
        "id": "bN4pZc7cP2vc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean 15.188679695129395 and std 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## General Amplitude = 6"
      ],
      "metadata": {
        "id": "q54LT3-nTCyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_synthetic_array_syn_range6=read_csv_file(csvs_syn_range6)\n",
        "X_syn_range6, dim_range6=get_synthetic_data(csvs_syn_range6, txts_syn_range6, df_synthetic_array_syn_range6)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd8472a3-7a5e-45dd-890e-fb27f87a945c",
        "id": "lE0GWp34TCyB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what merged so far:  (4840, 5801)\n",
            "what merged so far:  (9680, 5801)\n",
            "what merged so far:  (14520, 5801)\n",
            "what merged so far:  (19360, 5801)\n",
            "what merged so far:  (24200, 5801)\n",
            "what merged so far:  (29040, 5801)\n",
            "what merged so far:  (33880, 5801)\n",
            "what merged so far:  (38720, 5801)\n",
            "final merge shape (41382, 5801)\n",
            "----------------------------------------\n",
            "Time Execution: \n",
            "--- 36.88 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_scaled_syn_range6 = scaler.transform(X_syn_range6) \n",
        "X_scaled_real = scaler.transform(X_real) \n",
        "print(X_scaled_syn_range6.shape)\n",
        "print(X_scaled_real.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "512426a0-c4dd-446d-e3f3-226f28c1f5a1",
        "id": "DaCBqObTTCyB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(41382, 5801)\n",
            "(418, 5801)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_range6 = np.concatenate((X_scaled_syn_range6, X_scaled_real), axis=0)\n",
        "X_range6 = X_range6[..., np.newaxis] \n",
        "\n",
        "print(X_range6.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afc8bc52-a629-48e9-a939-d6041ed3dfef",
        "id": "YQ6oMGF_TCyC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(41800, 5801, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_synthetic = ([i for i in range(4,61)]*3)*1\n",
        "y_syn = [label_synthetic[i//dim_range6] for i in range(len(label_synthetic)*dim_range6)]\n",
        "\n",
        "y=y_syn+y_real\n",
        "print(len(y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4153a54-06b4-4d59-b6bf-b61d4851b5e4",
        "id": "cQcjRgZvTCyC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test=train_test_split(X_range6,y, test_size=0.3, \n",
        "                                                  shuffle=True, random_state=1)\n",
        "# X_train, X_val, y_train, y_val=train_test_split(X_train,y_train, test_size=0.2, \n",
        "#                                                   shuffle=True, random_state=1)\n"
      ],
      "metadata": {
        "id": "-Sv9yhm4TCyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "\n",
        "print(\"X_train:\",X_train.shape, \"y_train:\",len(y_train))\n",
        "print(\"X_test:\",X_test.shape, \"y_test:\",len(y_test))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49f098ed-8030-4683-d50f-66d6d5cb81e9",
        "id": "wZWZY8UOTCyD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (29260, 5801, 1) y_train: 29260\n",
            "X_test: (12540, 5801, 1) y_test: 12540\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Merge inputs and targets\n",
        "inputs = np.concatenate((X_train, X_test), axis=0)\n",
        "targets = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=5, shuffle=True)\n",
        "loss_per_fold=[]\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "es = EarlyStopping(monitor='val_loss', mode='min',verbose=1, patience=5)\n",
        "\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "\n",
        "  # Define the model architecture\n",
        "  model = create_model()\n",
        "\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit(inputs[train], targets[train], validation_data=(inputs[test], targets[test]), batch_size=254, epochs =50, \n",
        "                      callbacks=[es])\n",
        "  # Generate generalization metrics\n",
        "  scores = model.evaluate(recorded_scaled, np.array(label_recorded), verbose=0)\n",
        "  # print(f'Score for fold {fold_no}: {model.metrics_names} of {scores}')\n",
        "  print(f'MY DATA: Score for fold {fold_no}: {model.metrics_names} of {scores}')\n",
        "  loss_per_fold.append(scores)\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fd50466-b799-457f-903e-4196a02da9f4",
        "id": "V_bBAda5TCyE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 10s 42ms/step - loss: 31.8752 - val_loss: 32.1347\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.7874 - val_loss: 32.1347\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.7874 - val_loss: 32.1347\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.7874 - val_loss: 32.1347\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.7874 - val_loss: 32.1347\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.7874 - val_loss: 32.1347\n",
            "Epoch 6: early stopping\n",
            "MY DATA: Score for fold 1: ['loss'] of 15.188679695129395\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 7s 41ms/step - loss: 32.2075 - val_loss: 31.7596\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8812 - val_loss: 31.7596\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8812 - val_loss: 31.7596\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8812 - val_loss: 31.7596\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8812 - val_loss: 31.7596\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8812 - val_loss: 31.7596\n",
            "Epoch 6: early stopping\n",
            "MY DATA: Score for fold 2: ['loss'] of 15.188679695129395\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 7s 40ms/step - loss: 32.0046 - val_loss: 31.6774\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.9018 - val_loss: 31.6774\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.9018 - val_loss: 31.6774\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.9018 - val_loss: 31.6774\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.9018 - val_loss: 31.6774\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.9018 - val_loss: 31.6774\n",
            "Epoch 6: early stopping\n",
            "MY DATA: Score for fold 3: ['loss'] of 15.188679695129395\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 7s 42ms/step - loss: 31.8096 - val_loss: 31.8795\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8512 - val_loss: 31.8795\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8512 - val_loss: 31.8795\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8512 - val_loss: 31.8795\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8512 - val_loss: 31.8795\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8512 - val_loss: 31.8795\n",
            "Epoch 6: early stopping\n",
            "MY DATA: Score for fold 4: ['loss'] of 15.188679695129395\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 7s 40ms/step - loss: 32.0078 - val_loss: 31.8333\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 31.8628 - val_loss: 31.8333\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8628 - val_loss: 31.8333\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8628 - val_loss: 31.8333\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8628 - val_loss: 31.8333\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 31.8628 - val_loss: 31.8333\n",
            "Epoch 6: early stopping\n",
            "MY DATA: Score for fold 5: ['loss'] of 15.188679695129395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_per_fold"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24391462-fbba-44b3-e043-09712af5a424",
        "id": "-bSb-dX5TCyE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[15.188679695129395,\n",
              " 15.188679695129395,\n",
              " 15.188679695129395,\n",
              " 15.188679695129395,\n",
              " 15.188679695129395]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"mean {np.mean(loss_per_fold)} and std {np.std(loss_per_fold)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8_J-JYEQtzc",
        "outputId": "d3076515-b7f0-4f5e-dd80-7fbf0532c04f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean 15.188679695129395 and std 0.0\n"
          ]
        }
      ]
    }
  ]
}